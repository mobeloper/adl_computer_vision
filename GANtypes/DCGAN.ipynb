{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5240ff1d",
   "metadata": {},
   "source": [
    "# DCGAN (Deep Convolutional GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43460953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a85a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),             # Converts PIL image to tensor\n",
    "    transforms.Normalize([0.5], [0.5]) # Normalize pixel values from [0,1] to [-1,1]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec8a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4501090.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 256471.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1737391.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 683206.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    datasets.MNIST('.', train=True, download=True, transform=transform),\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#image size: 28x28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db143af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator (for MNIST - 28x28 output)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=1, feature_g=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            #                (inputDim, OutputChannel, kernelSize, stride, padding)\n",
    "            # nn.ConvTranspose2d(100, 256, 3, 1, 0)\n",
    "            nn.ConvTranspose2d(z_dim, feature_g * 4, 3, 1, 0),     # 1x1 → 3x3\n",
    "            nn.BatchNorm2d(feature_g * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            #OutputSize = (7-1)* 2 + 4-2*1 = 14\n",
    "\n",
    "            # nn.ConvTranspose2d(256, 128, 4,2,1)\n",
    "            nn.ConvTranspose2d(feature_g * 4, feature_g * 2, 4, 2, 1),  # 3x3 → 7x7\n",
    "            nn.BatchNorm2d(feature_g * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # nn.ConvTranspose2d(128, 64, 4,2,1)\n",
    "            nn.ConvTranspose2d(feature_g * 2, feature_g, 4, 2, 1),      # 7x7 → 14x14  \n",
    "            nn.BatchNorm2d(feature_g),\n",
    "            nn.ReLU(True),\n",
    "            # nn.ConvTranspose2d(64, 1, 4,2,1)\n",
    "            nn.ConvTranspose2d(feature_g, img_channels, 4, 2, 1),       # 14x14 → 28x28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "# Discriminator (for MNIST - 28x28 input)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_d=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, feature_d, 4, 2, 1),       # 28x28 → 14x14\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(feature_d, feature_d * 2, 4, 2, 1),       # 14x14 → 7x7\n",
    "            nn.BatchNorm2d(feature_d * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # nn.Conv2d(feature_d * 2, 1, 7, 1, 0),               # 7x7 → 1x1\n",
    "            nn.Conv2d(feature_d * 2, 1, 3, 1, 0),               # 7x7 → 1x1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return self.net(x).view(-1, 1)\n",
    "        return self.net(x).mean([2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e932e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc44fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100                    # Size of the noise vector input to Generator\n",
    "\n",
    "G = Generator(noise_dim).to(device)\n",
    "\n",
    "D = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bd1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()          # Binary Cross-Entropy for classification\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adfeeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss D: 1.4467, Loss G: 0.7969\n",
      "Epoch [1/50], Loss D: 1.5065, Loss G: 0.6771\n",
      "Epoch [1/50], Loss D: 1.4965, Loss G: 0.6563\n",
      "Epoch [1/50], Loss D: 1.4436, Loss G: 0.6788\n",
      "Epoch [1/50], Loss D: 1.3824, Loss G: 0.7158\n",
      "Epoch [1/50], Loss D: 1.3210, Loss G: 0.7572\n",
      "Epoch [1/50], Loss D: 1.2508, Loss G: 0.8124\n",
      "Epoch [1/50], Loss D: 1.1793, Loss G: 0.8772\n",
      "Epoch [1/50], Loss D: 1.1165, Loss G: 0.9366\n",
      "Epoch [1/50], Loss D: 1.0560, Loss G: 0.9940\n",
      "Epoch [1/50], Loss D: 1.0228, Loss G: 1.0291\n",
      "Epoch [1/50], Loss D: 0.9807, Loss G: 1.0623\n",
      "Epoch [1/50], Loss D: 0.9737, Loss G: 1.0675\n",
      "Epoch [1/50], Loss D: 0.9689, Loss G: 1.0528\n",
      "Epoch [1/50], Loss D: 0.9665, Loss G: 1.0413\n",
      "Epoch [1/50], Loss D: 0.9638, Loss G: 1.0399\n",
      "Epoch [1/50], Loss D: 0.9620, Loss G: 1.0357\n",
      "Epoch [1/50], Loss D: 0.9372, Loss G: 1.0705\n",
      "Epoch [1/50], Loss D: 0.9061, Loss G: 1.1123\n",
      "Epoch [1/50], Loss D: 0.8866, Loss G: 1.1386\n",
      "Epoch [1/50], Loss D: 0.8720, Loss G: 1.1709\n",
      "Epoch [1/50], Loss D: 0.8434, Loss G: 1.2007\n",
      "Epoch [1/50], Loss D: 0.8424, Loss G: 1.2007\n",
      "Epoch [1/50], Loss D: 0.8535, Loss G: 1.1670\n",
      "Epoch [1/50], Loss D: 0.8496, Loss G: 1.1702\n",
      "Epoch [1/50], Loss D: 0.8362, Loss G: 1.2073\n",
      "Epoch [1/50], Loss D: 0.8094, Loss G: 1.2465\n",
      "Epoch [1/50], Loss D: 0.8000, Loss G: 1.2475\n",
      "Epoch [1/50], Loss D: 0.8064, Loss G: 1.2486\n",
      "Epoch [1/50], Loss D: 0.7973, Loss G: 1.2517\n",
      "Epoch [1/50], Loss D: 0.7969, Loss G: 1.2317\n",
      "Epoch [1/50], Loss D: 0.7823, Loss G: 1.2406\n",
      "Epoch [1/50], Loss D: 0.7671, Loss G: 1.2747\n",
      "Epoch [1/50], Loss D: 0.7546, Loss G: 1.2905\n",
      "Epoch [1/50], Loss D: 0.7475, Loss G: 1.2921\n",
      "Epoch [1/50], Loss D: 0.7497, Loss G: 1.2754\n",
      "Epoch [1/50], Loss D: 0.7585, Loss G: 1.2504\n",
      "Epoch [1/50], Loss D: 0.7621, Loss G: 1.2378\n",
      "Epoch [1/50], Loss D: 0.7449, Loss G: 1.2670\n",
      "Epoch [1/50], Loss D: 0.7217, Loss G: 1.3111\n",
      "Epoch [1/50], Loss D: 0.7065, Loss G: 1.3690\n",
      "Epoch [1/50], Loss D: 0.6737, Loss G: 1.4183\n",
      "Epoch [1/50], Loss D: 0.6588, Loss G: 1.4528\n",
      "Epoch [1/50], Loss D: 0.6420, Loss G: 1.4894\n",
      "Epoch [1/50], Loss D: 0.6279, Loss G: 1.5403\n",
      "Epoch [1/50], Loss D: 0.5910, Loss G: 1.6234\n",
      "Epoch [1/50], Loss D: 0.5638, Loss G: 1.7098\n",
      "Epoch [1/50], Loss D: 0.5454, Loss G: 1.7823\n",
      "Epoch [1/50], Loss D: 0.5187, Loss G: 1.8410\n",
      "Epoch [1/50], Loss D: 0.5097, Loss G: 1.8896\n",
      "Epoch [1/50], Loss D: 0.4879, Loss G: 1.9165\n",
      "Epoch [1/50], Loss D: 0.4796, Loss G: 1.9485\n",
      "Epoch [1/50], Loss D: 0.4586, Loss G: 1.9772\n",
      "Epoch [1/50], Loss D: 0.4521, Loss G: 1.9852\n",
      "Epoch [1/50], Loss D: 0.4380, Loss G: 1.9842\n",
      "Epoch [1/50], Loss D: 0.4309, Loss G: 1.9958\n",
      "Epoch [1/50], Loss D: 0.4227, Loss G: 2.0228\n",
      "Epoch [1/50], Loss D: 0.4069, Loss G: 2.0517\n",
      "Epoch [1/50], Loss D: 0.3885, Loss G: 2.0614\n",
      "Epoch [1/50], Loss D: 0.3917, Loss G: 2.0386\n",
      "Epoch [1/50], Loss D: 0.3963, Loss G: 1.9568\n",
      "Epoch [1/50], Loss D: 0.4087, Loss G: 1.8626\n",
      "Epoch [1/50], Loss D: 0.4301, Loss G: 1.7664\n",
      "Epoch [1/50], Loss D: 0.4414, Loss G: 1.6620\n",
      "Epoch [1/50], Loss D: 0.4639, Loss G: 1.5826\n",
      "Epoch [1/50], Loss D: 0.4746, Loss G: 1.5517\n",
      "Epoch [1/50], Loss D: 0.4552, Loss G: 1.6035\n",
      "Epoch [1/50], Loss D: 0.4360, Loss G: 1.6951\n",
      "Epoch [1/50], Loss D: 0.4005, Loss G: 1.7992\n",
      "Epoch [1/50], Loss D: 0.3862, Loss G: 1.8973\n",
      "Epoch [1/50], Loss D: 0.3704, Loss G: 1.9620\n",
      "Epoch [1/50], Loss D: 0.3664, Loss G: 2.0011\n",
      "Epoch [1/50], Loss D: 0.3672, Loss G: 2.0132\n",
      "Epoch [1/50], Loss D: 0.3548, Loss G: 2.0389\n",
      "Epoch [1/50], Loss D: 0.3413, Loss G: 2.1078\n",
      "Epoch [1/50], Loss D: 0.3281, Loss G: 2.1777\n",
      "Epoch [1/50], Loss D: 0.3134, Loss G: 2.2502\n",
      "Epoch [1/50], Loss D: 0.3065, Loss G: 2.2967\n",
      "Epoch [1/50], Loss D: 0.3063, Loss G: 2.2818\n",
      "Epoch [1/50], Loss D: 0.3176, Loss G: 2.1742\n",
      "Epoch [1/50], Loss D: 0.3492, Loss G: 1.9788\n",
      "Epoch [1/50], Loss D: 0.4136, Loss G: 1.7021\n",
      "Epoch [1/50], Loss D: 0.4672, Loss G: 1.5328\n",
      "Epoch [1/50], Loss D: 0.4998, Loss G: 1.4252\n",
      "Epoch [1/50], Loss D: 0.5386, Loss G: 1.3276\n",
      "Epoch [1/50], Loss D: 0.5740, Loss G: 1.2395\n",
      "Epoch [1/50], Loss D: 0.5992, Loss G: 1.1958\n",
      "Epoch [1/50], Loss D: 0.6049, Loss G: 1.1994\n",
      "Epoch [1/50], Loss D: 0.6012, Loss G: 1.2238\n",
      "Epoch [1/50], Loss D: 0.5827, Loss G: 1.2757\n",
      "Epoch [1/50], Loss D: 0.5555, Loss G: 1.3389\n",
      "Epoch [1/50], Loss D: 0.5301, Loss G: 1.4125\n",
      "Epoch [1/50], Loss D: 0.5041, Loss G: 1.4953\n",
      "Epoch [1/50], Loss D: 0.4651, Loss G: 1.5922\n",
      "Epoch [1/50], Loss D: 0.4348, Loss G: 1.6865\n",
      "Epoch [1/50], Loss D: 0.4016, Loss G: 1.7577\n",
      "Epoch [1/50], Loss D: 0.4014, Loss G: 1.8005\n",
      "Epoch [1/50], Loss D: 0.3962, Loss G: 1.8346\n",
      "Epoch [1/50], Loss D: 0.3837, Loss G: 1.8617\n",
      "Epoch [1/50], Loss D: 0.3806, Loss G: 1.8895\n",
      "Epoch [1/50], Loss D: 0.3644, Loss G: 1.9157\n",
      "Epoch [1/50], Loss D: 0.3596, Loss G: 1.9346\n",
      "Epoch [1/50], Loss D: 0.3515, Loss G: 1.9443\n",
      "Epoch [1/50], Loss D: 0.3594, Loss G: 1.9308\n",
      "Epoch [1/50], Loss D: 0.3481, Loss G: 1.9325\n",
      "Epoch [1/50], Loss D: 0.3405, Loss G: 1.9565\n",
      "Epoch [1/50], Loss D: 0.3311, Loss G: 1.9856\n",
      "Epoch [1/50], Loss D: 0.3257, Loss G: 1.9960\n",
      "Epoch [1/50], Loss D: 0.3276, Loss G: 1.9828\n",
      "Epoch [1/50], Loss D: 0.3268, Loss G: 1.9315\n",
      "Epoch [1/50], Loss D: 0.3385, Loss G: 1.8800\n",
      "Epoch [1/50], Loss D: 0.3378, Loss G: 1.8717\n",
      "Epoch [1/50], Loss D: 0.3446, Loss G: 1.8630\n",
      "Epoch [1/50], Loss D: 0.3498, Loss G: 1.8602\n",
      "Epoch [1/50], Loss D: 0.3711, Loss G: 1.7701\n",
      "Epoch [1/50], Loss D: 0.3820, Loss G: 1.7424\n",
      "Epoch [1/50], Loss D: 0.3663, Loss G: 1.8127\n",
      "Epoch [1/50], Loss D: 0.3295, Loss G: 1.9773\n",
      "Epoch [1/50], Loss D: 0.2918, Loss G: 2.1742\n",
      "Epoch [1/50], Loss D: 0.2682, Loss G: 2.3500\n",
      "Epoch [1/50], Loss D: 0.2431, Loss G: 2.5007\n",
      "Epoch [1/50], Loss D: 0.2214, Loss G: 2.6404\n",
      "Epoch [1/50], Loss D: 0.2037, Loss G: 2.7670\n",
      "Epoch [1/50], Loss D: 0.1957, Loss G: 2.8676\n",
      "Epoch [1/50], Loss D: 0.1879, Loss G: 2.9200\n",
      "Epoch [1/50], Loss D: 0.1904, Loss G: 2.8690\n",
      "Epoch [1/50], Loss D: 0.2053, Loss G: 2.6844\n",
      "Epoch [1/50], Loss D: 0.2186, Loss G: 2.5474\n",
      "Epoch [1/50], Loss D: 0.2184, Loss G: 2.5646\n",
      "Epoch [1/50], Loss D: 0.2097, Loss G: 2.6238\n",
      "Epoch [1/50], Loss D: 0.1981, Loss G: 2.6975\n",
      "Epoch [1/50], Loss D: 0.1922, Loss G: 2.7646\n",
      "Epoch [1/50], Loss D: 0.1848, Loss G: 2.8434\n",
      "Epoch [1/50], Loss D: 0.1773, Loss G: 2.9238\n",
      "Epoch [1/50], Loss D: 0.1690, Loss G: 3.0159\n",
      "Epoch [1/50], Loss D: 0.1607, Loss G: 3.1247\n",
      "Epoch [1/50], Loss D: 0.1511, Loss G: 3.2371\n",
      "Epoch [1/50], Loss D: 0.1386, Loss G: 3.3338\n",
      "Epoch [1/50], Loss D: 0.1368, Loss G: 3.3884\n",
      "Epoch [1/50], Loss D: 0.1312, Loss G: 3.4148\n",
      "Epoch [1/50], Loss D: 0.1247, Loss G: 3.4074\n",
      "Epoch [1/50], Loss D: 0.1239, Loss G: 3.3890\n",
      "Epoch [1/50], Loss D: 0.1242, Loss G: 3.3825\n",
      "Epoch [1/50], Loss D: 0.1216, Loss G: 3.3948\n",
      "Epoch [1/50], Loss D: 0.1129, Loss G: 3.4329\n",
      "Epoch [1/50], Loss D: 0.1103, Loss G: 3.4929\n",
      "Epoch [1/50], Loss D: 0.1063, Loss G: 3.5400\n",
      "Epoch [1/50], Loss D: 0.1070, Loss G: 3.5725\n",
      "Epoch [1/50], Loss D: 0.0974, Loss G: 3.5877\n",
      "Epoch [1/50], Loss D: 0.1001, Loss G: 3.5942\n",
      "Epoch [1/50], Loss D: 0.0933, Loss G: 3.5941\n",
      "Epoch [1/50], Loss D: 0.0914, Loss G: 3.5998\n",
      "Epoch [1/50], Loss D: 0.0892, Loss G: 3.6212\n",
      "Epoch [1/50], Loss D: 0.0861, Loss G: 3.6446\n",
      "Epoch [1/50], Loss D: 0.0819, Loss G: 3.6664\n",
      "Epoch [1/50], Loss D: 0.0772, Loss G: 3.6867\n",
      "Epoch [1/50], Loss D: 0.0784, Loss G: 3.7059\n",
      "Epoch [1/50], Loss D: 0.0776, Loss G: 3.7181\n",
      "Epoch [1/50], Loss D: 0.0748, Loss G: 3.7128\n",
      "Epoch [1/50], Loss D: 0.0727, Loss G: 3.6648\n",
      "Epoch [1/50], Loss D: 0.0767, Loss G: 3.5308\n",
      "Epoch [1/50], Loss D: 0.0824, Loss G: 3.4291\n",
      "Epoch [1/50], Loss D: 0.0791, Loss G: 3.4317\n",
      "Epoch [1/50], Loss D: 0.0793, Loss G: 3.4204\n",
      "Epoch [1/50], Loss D: 0.0781, Loss G: 3.4022\n",
      "Epoch [1/50], Loss D: 0.0762, Loss G: 3.4576\n",
      "Epoch [1/50], Loss D: 0.0766, Loss G: 3.4885\n",
      "Epoch [1/50], Loss D: 0.0714, Loss G: 3.5171\n",
      "Epoch [1/50], Loss D: 0.0733, Loss G: 3.5427\n",
      "Epoch [1/50], Loss D: 0.0687, Loss G: 3.5874\n",
      "Epoch [1/50], Loss D: 0.0679, Loss G: 3.6190\n",
      "Epoch [1/50], Loss D: 0.0707, Loss G: 3.5750\n",
      "Epoch [1/50], Loss D: 0.0728, Loss G: 3.4304\n",
      "Epoch [1/50], Loss D: 0.0802, Loss G: 3.2880\n",
      "Epoch [1/50], Loss D: 0.0845, Loss G: 3.2163\n",
      "Epoch [1/50], Loss D: 0.0861, Loss G: 3.1583\n",
      "Epoch [1/50], Loss D: 0.0937, Loss G: 3.1028\n",
      "Epoch [1/50], Loss D: 0.0942, Loss G: 3.0476\n",
      "Epoch [1/50], Loss D: 0.1008, Loss G: 2.9872\n",
      "Epoch [1/50], Loss D: 0.1072, Loss G: 2.9327\n",
      "Epoch [1/50], Loss D: 0.1049, Loss G: 2.9371\n",
      "Epoch [1/50], Loss D: 0.1075, Loss G: 2.9708\n",
      "Epoch [1/50], Loss D: 0.1160, Loss G: 2.8618\n",
      "Epoch [1/50], Loss D: 0.1541, Loss G: 2.5441\n",
      "Epoch [1/50], Loss D: 0.1956, Loss G: 2.3004\n",
      "Epoch [1/50], Loss D: 0.2010, Loss G: 2.3319\n",
      "Epoch [1/50], Loss D: 0.1768, Loss G: 2.5404\n",
      "Epoch [1/50], Loss D: 0.1539, Loss G: 2.7517\n",
      "Epoch [1/50], Loss D: 0.1416, Loss G: 2.9223\n",
      "Epoch [1/50], Loss D: 0.1298, Loss G: 3.0240\n",
      "Epoch [1/50], Loss D: 0.1357, Loss G: 3.0582\n",
      "Epoch [1/50], Loss D: 0.1309, Loss G: 3.0904\n",
      "Epoch [1/50], Loss D: 0.1302, Loss G: 3.1229\n",
      "Epoch [1/50], Loss D: 0.1395, Loss G: 3.0583\n",
      "Epoch [1/50], Loss D: 0.1659, Loss G: 2.7545\n",
      "Epoch [1/50], Loss D: 0.2395, Loss G: 2.1596\n",
      "Epoch [1/50], Loss D: 0.3063, Loss G: 1.8466\n",
      "Epoch [1/50], Loss D: 0.3723, Loss G: 1.6496\n",
      "Epoch [1/50], Loss D: 0.4108, Loss G: 1.5636\n",
      "Epoch [1/50], Loss D: 0.4253, Loss G: 1.5399\n",
      "Epoch [1/50], Loss D: 0.4735, Loss G: 1.4431\n",
      "Epoch [1/50], Loss D: 0.5165, Loss G: 1.3508\n",
      "Epoch [1/50], Loss D: 0.5364, Loss G: 1.3729\n",
      "Epoch [1/50], Loss D: 0.5025, Loss G: 1.5355\n",
      "Epoch [1/50], Loss D: 0.4680, Loss G: 1.7245\n",
      "Epoch [1/50], Loss D: 0.4455, Loss G: 1.8551\n",
      "Epoch [1/50], Loss D: 0.4340, Loss G: 1.9861\n",
      "Epoch [1/50], Loss D: 0.3779, Loss G: 2.2728\n",
      "Epoch [1/50], Loss D: 0.3470, Loss G: 2.4412\n",
      "Epoch [1/50], Loss D: 0.3380, Loss G: 2.4285\n",
      "Epoch [1/50], Loss D: 0.3175, Loss G: 2.5001\n",
      "Epoch [1/50], Loss D: 0.3121, Loss G: 2.5340\n",
      "Epoch [1/50], Loss D: 0.3498, Loss G: 2.4327\n",
      "Epoch [1/50], Loss D: 0.3680, Loss G: 2.2713\n",
      "Epoch [1/50], Loss D: 0.3768, Loss G: 2.1991\n",
      "Epoch [1/50], Loss D: 0.3897, Loss G: 2.1136\n",
      "Epoch [1/50], Loss D: 0.3912, Loss G: 2.1062\n",
      "Epoch [1/50], Loss D: 0.3878, Loss G: 2.0816\n",
      "Epoch [1/50], Loss D: 0.3911, Loss G: 2.0540\n",
      "Epoch [1/50], Loss D: 0.3951, Loss G: 1.9982\n",
      "Epoch [1/50], Loss D: 0.3852, Loss G: 1.9811\n",
      "Epoch [1/50], Loss D: 0.3787, Loss G: 1.9736\n",
      "Epoch [1/50], Loss D: 0.3897, Loss G: 1.9964\n",
      "Epoch [1/50], Loss D: 0.3525, Loss G: 2.0310\n",
      "Epoch [1/50], Loss D: 0.3569, Loss G: 2.0671\n",
      "Epoch [1/50], Loss D: 0.3344, Loss G: 2.1316\n",
      "Epoch [1/50], Loss D: 0.3133, Loss G: 2.1765\n",
      "Epoch [1/50], Loss D: 0.3029, Loss G: 2.2589\n",
      "Epoch [1/50], Loss D: 0.3032, Loss G: 2.3190\n",
      "Epoch [1/50], Loss D: 0.2918, Loss G: 2.3815\n",
      "Epoch [1/50], Loss D: 0.2917, Loss G: 2.4225\n",
      "Epoch [1/50], Loss D: 0.2659, Loss G: 2.4797\n",
      "Epoch [1/50], Loss D: 0.2528, Loss G: 2.5302\n",
      "Epoch [1/50], Loss D: 0.2406, Loss G: 2.5443\n",
      "Epoch [1/50], Loss D: 0.2477, Loss G: 2.5307\n",
      "Epoch [1/50], Loss D: 0.2576, Loss G: 2.5356\n",
      "Epoch [1/50], Loss D: 0.2480, Loss G: 2.4811\n",
      "Epoch [1/50], Loss D: 0.2480, Loss G: 2.4424\n",
      "Epoch [1/50], Loss D: 0.2467, Loss G: 2.4118\n",
      "Epoch [1/50], Loss D: 0.2573, Loss G: 2.3789\n",
      "Epoch [1/50], Loss D: 0.2541, Loss G: 2.3675\n",
      "Epoch [1/50], Loss D: 0.2481, Loss G: 2.3562\n",
      "Epoch [1/50], Loss D: 0.2517, Loss G: 2.3801\n",
      "Epoch [1/50], Loss D: 0.2412, Loss G: 2.3805\n",
      "Epoch [1/50], Loss D: 0.2445, Loss G: 2.3694\n",
      "Epoch [1/50], Loss D: 0.2348, Loss G: 2.3651\n",
      "Epoch [1/50], Loss D: 0.2548, Loss G: 2.3209\n",
      "Epoch [1/50], Loss D: 0.2532, Loss G: 2.2377\n",
      "Epoch [1/50], Loss D: 0.2672, Loss G: 2.1361\n",
      "Epoch [1/50], Loss D: 0.2593, Loss G: 2.0756\n",
      "Epoch [1/50], Loss D: 0.2763, Loss G: 2.0287\n",
      "Epoch [1/50], Loss D: 0.2818, Loss G: 1.9858\n",
      "Epoch [1/50], Loss D: 0.2770, Loss G: 1.9861\n",
      "Epoch [1/50], Loss D: 0.2827, Loss G: 1.9759\n",
      "Epoch [1/50], Loss D: 0.2726, Loss G: 1.9659\n",
      "Epoch [1/50], Loss D: 0.2802, Loss G: 1.9549\n",
      "Epoch [1/50], Loss D: 0.2746, Loss G: 1.9522\n",
      "Epoch [1/50], Loss D: 0.2774, Loss G: 1.9573\n",
      "Epoch [1/50], Loss D: 0.2701, Loss G: 1.9658\n",
      "Epoch [1/50], Loss D: 0.2698, Loss G: 1.9721\n",
      "Epoch [1/50], Loss D: 0.2687, Loss G: 1.9605\n",
      "Epoch [1/50], Loss D: 0.2794, Loss G: 1.9590\n",
      "Epoch [1/50], Loss D: 0.2673, Loss G: 1.9420\n",
      "Epoch [1/50], Loss D: 0.2736, Loss G: 1.9338\n",
      "Epoch [1/50], Loss D: 0.2631, Loss G: 1.9180\n",
      "Epoch [1/50], Loss D: 0.2678, Loss G: 1.9177\n",
      "Epoch [1/50], Loss D: 0.2632, Loss G: 1.9205\n",
      "Epoch [1/50], Loss D: 0.2652, Loss G: 1.9369\n",
      "Epoch [1/50], Loss D: 0.2607, Loss G: 1.9636\n",
      "Epoch [1/50], Loss D: 0.2613, Loss G: 1.9815\n",
      "Epoch [1/50], Loss D: 0.2538, Loss G: 2.0287\n",
      "Epoch [1/50], Loss D: 0.2358, Loss G: 2.0711\n",
      "Epoch [1/50], Loss D: 0.2429, Loss G: 2.1045\n",
      "Epoch [1/50], Loss D: 0.2369, Loss G: 2.1246\n",
      "Epoch [1/50], Loss D: 0.2410, Loss G: 2.1650\n",
      "Epoch [1/50], Loss D: 0.2328, Loss G: 2.2189\n",
      "Epoch [1/50], Loss D: 0.2281, Loss G: 2.2524\n",
      "Epoch [1/50], Loss D: 0.2121, Loss G: 2.3064\n",
      "Epoch [1/50], Loss D: 0.2152, Loss G: 2.3503\n",
      "Epoch [1/50], Loss D: 0.2092, Loss G: 2.3795\n",
      "Epoch [1/50], Loss D: 0.2077, Loss G: 2.4176\n",
      "Epoch [1/50], Loss D: 0.2045, Loss G: 2.4078\n",
      "Epoch [1/50], Loss D: 0.2103, Loss G: 2.4097\n",
      "Epoch [1/50], Loss D: 0.2195, Loss G: 2.3451\n",
      "Epoch [1/50], Loss D: 0.2150, Loss G: 2.3412\n",
      "Epoch [1/50], Loss D: 0.2211, Loss G: 2.3388\n",
      "Epoch [1/50], Loss D: 0.2157, Loss G: 2.4124\n",
      "Epoch [1/50], Loss D: 0.1983, Loss G: 2.5076\n",
      "Epoch [1/50], Loss D: 0.1969, Loss G: 2.5832\n",
      "Epoch [1/50], Loss D: 0.1819, Loss G: 2.6843\n",
      "Epoch [1/50], Loss D: 0.1773, Loss G: 2.7719\n",
      "Epoch [1/50], Loss D: 0.1734, Loss G: 2.8087\n",
      "Epoch [1/50], Loss D: 0.1651, Loss G: 2.8632\n",
      "Epoch [1/50], Loss D: 0.1604, Loss G: 2.8582\n",
      "Epoch [1/50], Loss D: 0.1720, Loss G: 2.8697\n",
      "Epoch [1/50], Loss D: 0.1680, Loss G: 2.8403\n",
      "Epoch [1/50], Loss D: 0.1641, Loss G: 2.8699\n",
      "Epoch [1/50], Loss D: 0.1568, Loss G: 2.8920\n",
      "Epoch [1/50], Loss D: 0.1564, Loss G: 2.8994\n",
      "Epoch [1/50], Loss D: 0.1542, Loss G: 2.9249\n",
      "Epoch [1/50], Loss D: 0.1617, Loss G: 2.8435\n",
      "Epoch [1/50], Loss D: 0.1526, Loss G: 2.9246\n",
      "Epoch [1/50], Loss D: 0.1588, Loss G: 2.8022\n",
      "Epoch [1/50], Loss D: 0.1594, Loss G: 2.8096\n",
      "Epoch [1/50], Loss D: 0.1587, Loss G: 2.7754\n",
      "Epoch [1/50], Loss D: 0.1548, Loss G: 2.7672\n",
      "Epoch [1/50], Loss D: 0.1627, Loss G: 2.7584\n",
      "Epoch [1/50], Loss D: 0.1621, Loss G: 2.7811\n",
      "Epoch [1/50], Loss D: 0.1582, Loss G: 2.7637\n",
      "Epoch [1/50], Loss D: 0.1557, Loss G: 2.8242\n",
      "Epoch [1/50], Loss D: 0.1535, Loss G: 2.8212\n",
      "Epoch [1/50], Loss D: 0.1545, Loss G: 2.8392\n",
      "Epoch [1/50], Loss D: 0.1537, Loss G: 2.8552\n",
      "Epoch [1/50], Loss D: 0.1516, Loss G: 2.8894\n",
      "Epoch [1/50], Loss D: 0.1549, Loss G: 2.8144\n",
      "Epoch [1/50], Loss D: 0.1526, Loss G: 2.8330\n",
      "Epoch [1/50], Loss D: 0.1478, Loss G: 2.8270\n",
      "Epoch [1/50], Loss D: 0.1481, Loss G: 2.8215\n",
      "Epoch [1/50], Loss D: 0.1554, Loss G: 2.7943\n",
      "Epoch [1/50], Loss D: 0.1483, Loss G: 2.8321\n",
      "Epoch [1/50], Loss D: 0.1592, Loss G: 2.8253\n",
      "Epoch [1/50], Loss D: 0.1563, Loss G: 2.7865\n",
      "Epoch [1/50], Loss D: 0.1560, Loss G: 2.7705\n",
      "Epoch [1/50], Loss D: 0.1556, Loss G: 2.7214\n",
      "Epoch [1/50], Loss D: 0.1569, Loss G: 2.7650\n",
      "Epoch [1/50], Loss D: 0.1556, Loss G: 2.7281\n",
      "Epoch [1/50], Loss D: 0.1663, Loss G: 2.7394\n",
      "Epoch [1/50], Loss D: 0.1647, Loss G: 2.6835\n",
      "Epoch [1/50], Loss D: 0.1741, Loss G: 2.6707\n",
      "Epoch [1/50], Loss D: 0.1721, Loss G: 2.6324\n",
      "Epoch [1/50], Loss D: 0.1621, Loss G: 2.7217\n",
      "Epoch [1/50], Loss D: 0.1681, Loss G: 2.7160\n",
      "Epoch [1/50], Loss D: 0.1564, Loss G: 2.7509\n",
      "Epoch [1/50], Loss D: 0.1626, Loss G: 2.7378\n",
      "Epoch [1/50], Loss D: 0.1669, Loss G: 2.7207\n",
      "Epoch [1/50], Loss D: 0.1629, Loss G: 2.7469\n",
      "Epoch [1/50], Loss D: 0.1664, Loss G: 2.7556\n",
      "Epoch [1/50], Loss D: 0.1645, Loss G: 2.6986\n",
      "Epoch [1/50], Loss D: 0.1622, Loss G: 2.7230\n",
      "Epoch [1/50], Loss D: 0.1693, Loss G: 2.6638\n",
      "Epoch [1/50], Loss D: 0.1754, Loss G: 2.6481\n",
      "Epoch [1/50], Loss D: 0.1770, Loss G: 2.5930\n",
      "Epoch [1/50], Loss D: 0.1952, Loss G: 2.5187\n",
      "Epoch [1/50], Loss D: 0.1913, Loss G: 2.5850\n",
      "Epoch [1/50], Loss D: 0.1824, Loss G: 2.6019\n",
      "Epoch [1/50], Loss D: 0.1950, Loss G: 2.5057\n",
      "Epoch [1/50], Loss D: 0.2002, Loss G: 2.5286\n",
      "Epoch [1/50], Loss D: 0.2137, Loss G: 2.4165\n",
      "Epoch [1/50], Loss D: 0.2093, Loss G: 2.4919\n",
      "Epoch [1/50], Loss D: 0.2258, Loss G: 2.4532\n",
      "Epoch [1/50], Loss D: 0.2325, Loss G: 2.3968\n",
      "Epoch [1/50], Loss D: 0.2288, Loss G: 2.4400\n",
      "Epoch [1/50], Loss D: 0.2395, Loss G: 2.4560\n",
      "Epoch [1/50], Loss D: 0.2432, Loss G: 2.5136\n",
      "Epoch [1/50], Loss D: 0.2348, Loss G: 2.6033\n",
      "Epoch [1/50], Loss D: 0.2330, Loss G: 2.6395\n",
      "Epoch [1/50], Loss D: 0.2536, Loss G: 2.5673\n",
      "Epoch [1/50], Loss D: 0.2569, Loss G: 2.5754\n",
      "Epoch [1/50], Loss D: 0.2489, Loss G: 2.5948\n",
      "Epoch [1/50], Loss D: 0.2622, Loss G: 2.5159\n",
      "Epoch [1/50], Loss D: 0.2676, Loss G: 2.4504\n",
      "Epoch [1/50], Loss D: 0.2807, Loss G: 2.4018\n",
      "Epoch [1/50], Loss D: 0.2750, Loss G: 2.4692\n",
      "Epoch [1/50], Loss D: 0.2513, Loss G: 2.6187\n",
      "Epoch [1/50], Loss D: 0.2713, Loss G: 2.4725\n",
      "Epoch [1/50], Loss D: 0.3094, Loss G: 2.3253\n",
      "Epoch [1/50], Loss D: 0.3226, Loss G: 2.2618\n",
      "Epoch [1/50], Loss D: 0.3164, Loss G: 2.3183\n",
      "Epoch [1/50], Loss D: 0.3024, Loss G: 2.3851\n",
      "Epoch [1/50], Loss D: 0.3313, Loss G: 2.2307\n",
      "Epoch [1/50], Loss D: 0.3116, Loss G: 2.3210\n",
      "Epoch [1/50], Loss D: 0.3467, Loss G: 2.2441\n",
      "Epoch [1/50], Loss D: 0.3514, Loss G: 2.2217\n",
      "Epoch [1/50], Loss D: 0.3728, Loss G: 2.1195\n",
      "Epoch [1/50], Loss D: 0.3499, Loss G: 2.2796\n",
      "Epoch [1/50], Loss D: 0.3434, Loss G: 2.3355\n",
      "Epoch [1/50], Loss D: 0.3491, Loss G: 2.3257\n",
      "Epoch [1/50], Loss D: 0.3232, Loss G: 2.3248\n",
      "Epoch [1/50], Loss D: 0.3472, Loss G: 2.2253\n",
      "Epoch [1/50], Loss D: 0.3329, Loss G: 2.2312\n",
      "Epoch [1/50], Loss D: 0.3466, Loss G: 2.1774\n",
      "Epoch [1/50], Loss D: 0.3381, Loss G: 2.1056\n",
      "Epoch [1/50], Loss D: 0.3426, Loss G: 2.1048\n",
      "Epoch [1/50], Loss D: 0.3327, Loss G: 2.1059\n",
      "Epoch [1/50], Loss D: 0.3511, Loss G: 2.0521\n",
      "Epoch [1/50], Loss D: 0.3660, Loss G: 1.9453\n",
      "Epoch [1/50], Loss D: 0.3319, Loss G: 2.0066\n",
      "Epoch [1/50], Loss D: 0.3448, Loss G: 1.9923\n",
      "Epoch [1/50], Loss D: 0.3668, Loss G: 1.9887\n",
      "Epoch [1/50], Loss D: 0.3368, Loss G: 2.0118\n",
      "Epoch [1/50], Loss D: 0.3484, Loss G: 1.9751\n",
      "Epoch [1/50], Loss D: 0.3790, Loss G: 1.9035\n",
      "Epoch [1/50], Loss D: 0.3740, Loss G: 1.9246\n",
      "Epoch [1/50], Loss D: 0.3904, Loss G: 1.9270\n",
      "Epoch [1/50], Loss D: 0.3920, Loss G: 1.9155\n",
      "Epoch [1/50], Loss D: 0.4304, Loss G: 1.9317\n",
      "Epoch [1/50], Loss D: 0.4386, Loss G: 1.9431\n",
      "Epoch [1/50], Loss D: 0.4292, Loss G: 2.0218\n",
      "Epoch [1/50], Loss D: 0.4243, Loss G: 2.0711\n",
      "Epoch [1/50], Loss D: 0.4698, Loss G: 2.0131\n",
      "Epoch [1/50], Loss D: 0.4783, Loss G: 2.0041\n",
      "Epoch [1/50], Loss D: 0.4681, Loss G: 1.9916\n",
      "Epoch [1/50], Loss D: 0.4802, Loss G: 1.9339\n",
      "Epoch [1/50], Loss D: 0.4834, Loss G: 1.9319\n",
      "Epoch [1/50], Loss D: 0.4919, Loss G: 1.8442\n",
      "Epoch [1/50], Loss D: 0.5065, Loss G: 1.8032\n",
      "Epoch [1/50], Loss D: 0.5465, Loss G: 1.6975\n",
      "Epoch [1/50], Loss D: 0.5321, Loss G: 1.6694\n",
      "Epoch [1/50], Loss D: 0.5610, Loss G: 1.6644\n",
      "Epoch [1/50], Loss D: 0.5702, Loss G: 1.7352\n",
      "Epoch [1/50], Loss D: 0.5924, Loss G: 1.7665\n",
      "Epoch [1/50], Loss D: 0.5986, Loss G: 1.8195\n",
      "Epoch [1/50], Loss D: 0.5449, Loss G: 1.9210\n",
      "Epoch [1/50], Loss D: 0.5785, Loss G: 1.9531\n",
      "Epoch [1/50], Loss D: 0.5190, Loss G: 1.9680\n",
      "Epoch [1/50], Loss D: 0.5461, Loss G: 1.9537\n",
      "Epoch [1/50], Loss D: 0.5283, Loss G: 1.9475\n",
      "Epoch [1/50], Loss D: 0.5323, Loss G: 2.0026\n",
      "Epoch [1/50], Loss D: 0.5179, Loss G: 1.9086\n",
      "Epoch [1/50], Loss D: 0.5108, Loss G: 1.9060\n",
      "Epoch [1/50], Loss D: 0.5818, Loss G: 1.8952\n",
      "Epoch [1/50], Loss D: 0.5357, Loss G: 1.8586\n",
      "Epoch [1/50], Loss D: 0.5585, Loss G: 1.8303\n",
      "Epoch [1/50], Loss D: 0.5365, Loss G: 1.8418\n",
      "Epoch [1/50], Loss D: 0.5690, Loss G: 1.8341\n",
      "Epoch [1/50], Loss D: 0.5597, Loss G: 1.7883\n",
      "Epoch [1/50], Loss D: 0.6053, Loss G: 1.7346\n",
      "Epoch [1/50], Loss D: 0.5973, Loss G: 1.7935\n",
      "Epoch [1/50], Loss D: 0.5927, Loss G: 1.8446\n",
      "Epoch [1/50], Loss D: 0.5955, Loss G: 1.7977\n",
      "Epoch [1/50], Loss D: 0.6206, Loss G: 1.8037\n",
      "Epoch [1/50], Loss D: 0.5851, Loss G: 1.8159\n",
      "Epoch [1/50], Loss D: 0.5986, Loss G: 1.8209\n",
      "Epoch [1/50], Loss D: 0.6055, Loss G: 1.8490\n",
      "Epoch [1/50], Loss D: 0.5799, Loss G: 1.8316\n",
      "Epoch [1/50], Loss D: 0.5799, Loss G: 1.7893\n",
      "Epoch [1/50], Loss D: 0.5407, Loss G: 1.8089\n",
      "Epoch [1/50], Loss D: 0.5149, Loss G: 1.8603\n",
      "Epoch [1/50], Loss D: 0.5019, Loss G: 1.9748\n",
      "Epoch [1/50], Loss D: 0.5187, Loss G: 1.9635\n",
      "Epoch [1/50], Loss D: 0.4418, Loss G: 2.0451\n",
      "Epoch [1/50], Loss D: 0.4393, Loss G: 2.1291\n",
      "Epoch [1/50], Loss D: 0.4080, Loss G: 2.2038\n",
      "Epoch [1/50], Loss D: 0.4365, Loss G: 2.1647\n",
      "Epoch [1/50], Loss D: 0.3786, Loss G: 2.3193\n",
      "Epoch [1/50], Loss D: 0.3884, Loss G: 2.3353\n",
      "Epoch [1/50], Loss D: 0.3829, Loss G: 2.3520\n",
      "Epoch [1/50], Loss D: 0.3702, Loss G: 2.4546\n",
      "Epoch [1/50], Loss D: 0.3832, Loss G: 2.4274\n",
      "Epoch [1/50], Loss D: 0.3412, Loss G: 2.4314\n",
      "Epoch [1/50], Loss D: 0.3454, Loss G: 2.4649\n",
      "Epoch [1/50], Loss D: 0.3167, Loss G: 2.4424\n",
      "Epoch [1/50], Loss D: 0.3420, Loss G: 2.4255\n",
      "Epoch [1/50], Loss D: 0.3138, Loss G: 2.4941\n",
      "Epoch [1/50], Loss D: 0.3122, Loss G: 2.4302\n",
      "Epoch [1/50], Loss D: 0.3169, Loss G: 2.4200\n",
      "Epoch [1/50], Loss D: 0.2980, Loss G: 2.4223\n",
      "Epoch [1/50], Loss D: 0.3252, Loss G: 2.3402\n",
      "Epoch [1/50], Loss D: 0.3317, Loss G: 2.2316\n",
      "Epoch [1/50], Loss D: 0.3302, Loss G: 2.3072\n",
      "Epoch [1/50], Loss D: 0.3167, Loss G: 2.3529\n",
      "Epoch [1/50], Loss D: 0.3248, Loss G: 2.3103\n",
      "Epoch [1/50], Loss D: 0.3204, Loss G: 2.3107\n",
      "Epoch [1/50], Loss D: 0.3314, Loss G: 2.2681\n",
      "Epoch [1/50], Loss D: 0.3180, Loss G: 2.2706\n",
      "Epoch [1/50], Loss D: 0.3363, Loss G: 2.2109\n",
      "Epoch [1/50], Loss D: 0.3088, Loss G: 2.2698\n",
      "Epoch [1/50], Loss D: 0.3522, Loss G: 2.2407\n",
      "Epoch [1/50], Loss D: 0.3414, Loss G: 2.2353\n",
      "Epoch [2/50], Loss D: 0.3403, Loss G: 2.2665\n",
      "Epoch [2/50], Loss D: 0.3355, Loss G: 2.2500\n",
      "Epoch [2/50], Loss D: 0.3685, Loss G: 2.1976\n",
      "Epoch [2/50], Loss D: 0.3248, Loss G: 2.2465\n",
      "Epoch [2/50], Loss D: 0.3585, Loss G: 2.2288\n",
      "Epoch [2/50], Loss D: 0.3381, Loss G: 2.2323\n",
      "Epoch [2/50], Loss D: 0.3608, Loss G: 2.2275\n",
      "Epoch [2/50], Loss D: 0.3443, Loss G: 2.2533\n",
      "Epoch [2/50], Loss D: 0.3761, Loss G: 2.1887\n",
      "Epoch [2/50], Loss D: 0.3712, Loss G: 2.2570\n",
      "Epoch [2/50], Loss D: 0.3798, Loss G: 2.2394\n",
      "Epoch [2/50], Loss D: 0.3782, Loss G: 2.1204\n",
      "Epoch [2/50], Loss D: 0.4083, Loss G: 2.1903\n",
      "Epoch [2/50], Loss D: 0.4028, Loss G: 2.1574\n",
      "Epoch [2/50], Loss D: 0.3814, Loss G: 2.1092\n",
      "Epoch [2/50], Loss D: 0.4220, Loss G: 2.0245\n",
      "Epoch [2/50], Loss D: 0.4554, Loss G: 2.0212\n",
      "Epoch [2/50], Loss D: 0.4344, Loss G: 2.0201\n",
      "Epoch [2/50], Loss D: 0.4428, Loss G: 2.1318\n",
      "Epoch [2/50], Loss D: 0.4614, Loss G: 2.1685\n",
      "Epoch [2/50], Loss D: 0.4292, Loss G: 2.1947\n",
      "Epoch [2/50], Loss D: 0.4730, Loss G: 2.1018\n",
      "Epoch [2/50], Loss D: 0.4706, Loss G: 2.1044\n",
      "Epoch [2/50], Loss D: 0.4608, Loss G: 2.1504\n",
      "Epoch [2/50], Loss D: 0.4616, Loss G: 2.0338\n",
      "Epoch [2/50], Loss D: 0.4883, Loss G: 1.9654\n",
      "Epoch [2/50], Loss D: 0.4521, Loss G: 1.9461\n",
      "Epoch [2/50], Loss D: 0.4472, Loss G: 1.9269\n",
      "Epoch [2/50], Loss D: 0.4463, Loss G: 1.9631\n",
      "Epoch [2/50], Loss D: 0.4204, Loss G: 2.0122\n",
      "Epoch [2/50], Loss D: 0.4339, Loss G: 2.0135\n",
      "Epoch [2/50], Loss D: 0.4351, Loss G: 2.0918\n",
      "Epoch [2/50], Loss D: 0.4043, Loss G: 2.0975\n",
      "Epoch [2/50], Loss D: 0.4146, Loss G: 2.1078\n",
      "Epoch [2/50], Loss D: 0.3891, Loss G: 2.0783\n",
      "Epoch [2/50], Loss D: 0.3745, Loss G: 2.1087\n",
      "Epoch [2/50], Loss D: 0.3954, Loss G: 2.0972\n",
      "Epoch [2/50], Loss D: 0.3719, Loss G: 2.1199\n",
      "Epoch [2/50], Loss D: 0.3725, Loss G: 2.1813\n",
      "Epoch [2/50], Loss D: 0.3359, Loss G: 2.2234\n",
      "Epoch [2/50], Loss D: 0.3695, Loss G: 2.2124\n",
      "Epoch [2/50], Loss D: 0.3727, Loss G: 2.2104\n",
      "Epoch [2/50], Loss D: 0.3663, Loss G: 2.1883\n",
      "Epoch [2/50], Loss D: 0.3392, Loss G: 2.2392\n",
      "Epoch [2/50], Loss D: 0.3343, Loss G: 2.2727\n",
      "Epoch [2/50], Loss D: 0.3184, Loss G: 2.2485\n",
      "Epoch [2/50], Loss D: 0.3148, Loss G: 2.2761\n",
      "Epoch [2/50], Loss D: 0.3155, Loss G: 2.2377\n",
      "Epoch [2/50], Loss D: 0.3194, Loss G: 2.2634\n",
      "Epoch [2/50], Loss D: 0.3362, Loss G: 2.2513\n",
      "Epoch [2/50], Loss D: 0.3066, Loss G: 2.3088\n",
      "Epoch [2/50], Loss D: 0.3058, Loss G: 2.3139\n",
      "Epoch [2/50], Loss D: 0.3111, Loss G: 2.3522\n",
      "Epoch [2/50], Loss D: 0.2962, Loss G: 2.2900\n",
      "Epoch [2/50], Loss D: 0.3015, Loss G: 2.3216\n",
      "Epoch [2/50], Loss D: 0.3019, Loss G: 2.3153\n",
      "Epoch [2/50], Loss D: 0.3038, Loss G: 2.3124\n",
      "Epoch [2/50], Loss D: 0.3098, Loss G: 2.2965\n",
      "Epoch [2/50], Loss D: 0.3381, Loss G: 2.2450\n",
      "Epoch [2/50], Loss D: 0.3386, Loss G: 2.1882\n",
      "Epoch [2/50], Loss D: 0.3491, Loss G: 2.2003\n",
      "Epoch [2/50], Loss D: 0.3811, Loss G: 2.2490\n",
      "Epoch [2/50], Loss D: 0.4132, Loss G: 2.2544\n",
      "Epoch [2/50], Loss D: 0.3869, Loss G: 2.2222\n",
      "Epoch [2/50], Loss D: 0.3879, Loss G: 2.2690\n",
      "Epoch [2/50], Loss D: 0.3794, Loss G: 2.2303\n",
      "Epoch [2/50], Loss D: 0.3616, Loss G: 2.3019\n",
      "Epoch [2/50], Loss D: 0.3792, Loss G: 2.3007\n",
      "Epoch [2/50], Loss D: 0.3823, Loss G: 2.1988\n",
      "Epoch [2/50], Loss D: 0.4053, Loss G: 2.1658\n",
      "Epoch [2/50], Loss D: 0.3756, Loss G: 2.1039\n",
      "Epoch [2/50], Loss D: 0.4010, Loss G: 2.0304\n",
      "Epoch [2/50], Loss D: 0.4329, Loss G: 1.9880\n",
      "Epoch [2/50], Loss D: 0.4231, Loss G: 1.9643\n",
      "Epoch [2/50], Loss D: 0.4799, Loss G: 1.9074\n",
      "Epoch [2/50], Loss D: 0.4792, Loss G: 1.9339\n",
      "Epoch [2/50], Loss D: 0.4743, Loss G: 1.9067\n",
      "Epoch [2/50], Loss D: 0.5107, Loss G: 1.9160\n",
      "Epoch [2/50], Loss D: 0.5230, Loss G: 2.0167\n",
      "Epoch [2/50], Loss D: 0.5693, Loss G: 1.8613\n",
      "Epoch [2/50], Loss D: 0.5673, Loss G: 1.9386\n",
      "Epoch [2/50], Loss D: 0.6207, Loss G: 1.9151\n",
      "Epoch [2/50], Loss D: 0.5894, Loss G: 2.0089\n",
      "Epoch [2/50], Loss D: 0.6187, Loss G: 2.0518\n",
      "Epoch [2/50], Loss D: 0.5761, Loss G: 2.0299\n",
      "Epoch [2/50], Loss D: 0.5748, Loss G: 2.0065\n",
      "Epoch [2/50], Loss D: 0.5712, Loss G: 1.9663\n",
      "Epoch [2/50], Loss D: 0.5572, Loss G: 2.0305\n",
      "Epoch [2/50], Loss D: 0.4793, Loss G: 2.1217\n",
      "Epoch [2/50], Loss D: 0.4501, Loss G: 2.2827\n",
      "Epoch [2/50], Loss D: 0.3947, Loss G: 2.3911\n",
      "Epoch [2/50], Loss D: 0.3759, Loss G: 2.4121\n",
      "Epoch [2/50], Loss D: 0.3677, Loss G: 2.4438\n",
      "Epoch [2/50], Loss D: 0.3582, Loss G: 2.4433\n",
      "Epoch [2/50], Loss D: 0.3342, Loss G: 2.4565\n",
      "Epoch [2/50], Loss D: 0.3027, Loss G: 2.4427\n",
      "Epoch [2/50], Loss D: 0.3285, Loss G: 2.2675\n",
      "Epoch [2/50], Loss D: 0.3260, Loss G: 2.2256\n",
      "Epoch [2/50], Loss D: 0.3346, Loss G: 2.1843\n",
      "Epoch [2/50], Loss D: 0.3604, Loss G: 2.0764\n",
      "Epoch [2/50], Loss D: 0.3549, Loss G: 2.0816\n",
      "Epoch [2/50], Loss D: 0.3721, Loss G: 2.0357\n",
      "Epoch [2/50], Loss D: 0.3917, Loss G: 2.0202\n",
      "Epoch [2/50], Loss D: 0.4001, Loss G: 2.0049\n",
      "Epoch [2/50], Loss D: 0.4116, Loss G: 2.0294\n",
      "Epoch [2/50], Loss D: 0.4340, Loss G: 2.0178\n",
      "Epoch [2/50], Loss D: 0.4232, Loss G: 1.9980\n",
      "Epoch [2/50], Loss D: 0.4419, Loss G: 2.1149\n",
      "Epoch [2/50], Loss D: 0.4694, Loss G: 2.0399\n",
      "Epoch [2/50], Loss D: 0.4490, Loss G: 2.0387\n",
      "Epoch [2/50], Loss D: 0.4825, Loss G: 1.9402\n",
      "Epoch [2/50], Loss D: 0.4896, Loss G: 1.9506\n",
      "Epoch [2/50], Loss D: 0.4735, Loss G: 1.9660\n",
      "Epoch [2/50], Loss D: 0.4886, Loss G: 1.9133\n",
      "Epoch [2/50], Loss D: 0.4608, Loss G: 1.9325\n",
      "Epoch [2/50], Loss D: 0.4773, Loss G: 1.9305\n",
      "Epoch [2/50], Loss D: 0.4471, Loss G: 1.9908\n",
      "Epoch [2/50], Loss D: 0.4689, Loss G: 1.9406\n",
      "Epoch [2/50], Loss D: 0.4654, Loss G: 1.9980\n",
      "Epoch [2/50], Loss D: 0.4532, Loss G: 2.0546\n",
      "Epoch [2/50], Loss D: 0.4427, Loss G: 2.0705\n",
      "Epoch [2/50], Loss D: 0.4444, Loss G: 2.0522\n",
      "Epoch [2/50], Loss D: 0.4271, Loss G: 2.0273\n",
      "Epoch [2/50], Loss D: 0.4280, Loss G: 1.9887\n",
      "Epoch [2/50], Loss D: 0.4214, Loss G: 2.0170\n",
      "Epoch [2/50], Loss D: 0.4219, Loss G: 2.0351\n",
      "Epoch [2/50], Loss D: 0.4193, Loss G: 1.9950\n",
      "Epoch [2/50], Loss D: 0.4342, Loss G: 2.0078\n",
      "Epoch [2/50], Loss D: 0.4213, Loss G: 2.0528\n",
      "Epoch [2/50], Loss D: 0.4434, Loss G: 2.0108\n",
      "Epoch [2/50], Loss D: 0.4326, Loss G: 2.0582\n",
      "Epoch [2/50], Loss D: 0.4899, Loss G: 1.9781\n",
      "Epoch [2/50], Loss D: 0.4565, Loss G: 2.0648\n",
      "Epoch [2/50], Loss D: 0.5003, Loss G: 2.0700\n",
      "Epoch [2/50], Loss D: 0.4768, Loss G: 2.1086\n",
      "Epoch [2/50], Loss D: 0.4758, Loss G: 2.1040\n",
      "Epoch [2/50], Loss D: 0.4750, Loss G: 2.0462\n",
      "Epoch [2/50], Loss D: 0.4830, Loss G: 2.0655\n",
      "Epoch [2/50], Loss D: 0.4714, Loss G: 1.9637\n",
      "Epoch [2/50], Loss D: 0.4848, Loss G: 1.9703\n",
      "Epoch [2/50], Loss D: 0.4792, Loss G: 1.9631\n",
      "Epoch [2/50], Loss D: 0.4739, Loss G: 1.9971\n",
      "Epoch [2/50], Loss D: 0.4765, Loss G: 2.0430\n",
      "Epoch [2/50], Loss D: 0.5005, Loss G: 2.0029\n",
      "Epoch [2/50], Loss D: 0.4507, Loss G: 2.0805\n",
      "Epoch [2/50], Loss D: 0.4613, Loss G: 2.0698\n",
      "Epoch [2/50], Loss D: 0.4660, Loss G: 2.0512\n",
      "Epoch [2/50], Loss D: 0.4675, Loss G: 2.0002\n",
      "Epoch [2/50], Loss D: 0.4719, Loss G: 1.9403\n",
      "Epoch [2/50], Loss D: 0.4750, Loss G: 1.9622\n",
      "Epoch [2/50], Loss D: 0.4738, Loss G: 1.9509\n",
      "Epoch [2/50], Loss D: 0.4733, Loss G: 1.9095\n",
      "Epoch [2/50], Loss D: 0.5135, Loss G: 1.9183\n",
      "Epoch [2/50], Loss D: 0.5033, Loss G: 1.9086\n",
      "Epoch [2/50], Loss D: 0.5405, Loss G: 1.8928\n",
      "Epoch [2/50], Loss D: 0.5262, Loss G: 1.9116\n",
      "Epoch [2/50], Loss D: 0.5558, Loss G: 1.9273\n",
      "Epoch [2/50], Loss D: 0.5459, Loss G: 1.9074\n",
      "Epoch [2/50], Loss D: 0.5265, Loss G: 1.9471\n",
      "Epoch [2/50], Loss D: 0.5390, Loss G: 1.8969\n",
      "Epoch [2/50], Loss D: 0.5457, Loss G: 1.8294\n",
      "Epoch [2/50], Loss D: 0.5436, Loss G: 1.7909\n",
      "Epoch [2/50], Loss D: 0.5052, Loss G: 1.8550\n",
      "Epoch [2/50], Loss D: 0.4959, Loss G: 1.8518\n",
      "Epoch [2/50], Loss D: 0.4869, Loss G: 1.8371\n",
      "Epoch [2/50], Loss D: 0.4975, Loss G: 1.8548\n",
      "Epoch [2/50], Loss D: 0.4859, Loss G: 1.9051\n",
      "Epoch [2/50], Loss D: 0.4597, Loss G: 1.8940\n",
      "Epoch [2/50], Loss D: 0.4654, Loss G: 1.9290\n",
      "Epoch [2/50], Loss D: 0.4403, Loss G: 1.9462\n",
      "Epoch [2/50], Loss D: 0.4374, Loss G: 1.9757\n",
      "Epoch [2/50], Loss D: 0.4060, Loss G: 2.0350\n",
      "Epoch [2/50], Loss D: 0.3992, Loss G: 2.0518\n",
      "Epoch [2/50], Loss D: 0.4066, Loss G: 2.0380\n",
      "Epoch [2/50], Loss D: 0.4094, Loss G: 2.0007\n",
      "Epoch [2/50], Loss D: 0.4011, Loss G: 2.0136\n",
      "Epoch [2/50], Loss D: 0.4033, Loss G: 1.9369\n",
      "Epoch [2/50], Loss D: 0.4002, Loss G: 1.9652\n",
      "Epoch [2/50], Loss D: 0.4058, Loss G: 1.9142\n",
      "Epoch [2/50], Loss D: 0.4129, Loss G: 1.8847\n",
      "Epoch [2/50], Loss D: 0.4113, Loss G: 1.9381\n",
      "Epoch [2/50], Loss D: 0.4280, Loss G: 1.9646\n",
      "Epoch [2/50], Loss D: 0.4062, Loss G: 1.9642\n",
      "Epoch [2/50], Loss D: 0.4455, Loss G: 1.9653\n",
      "Epoch [2/50], Loss D: 0.4589, Loss G: 1.9943\n",
      "Epoch [2/50], Loss D: 0.4803, Loss G: 1.9799\n",
      "Epoch [2/50], Loss D: 0.5152, Loss G: 1.8860\n",
      "Epoch [2/50], Loss D: 0.5357, Loss G: 1.8878\n",
      "Epoch [2/50], Loss D: 0.5617, Loss G: 1.8396\n",
      "Epoch [2/50], Loss D: 0.5764, Loss G: 1.8159\n",
      "Epoch [2/50], Loss D: 0.5741, Loss G: 1.6949\n",
      "Epoch [2/50], Loss D: 0.6344, Loss G: 1.6530\n",
      "Epoch [2/50], Loss D: 0.6154, Loss G: 1.6917\n",
      "Epoch [2/50], Loss D: 0.6364, Loss G: 1.6450\n",
      "Epoch [2/50], Loss D: 0.6251, Loss G: 1.6744\n",
      "Epoch [2/50], Loss D: 0.6093, Loss G: 1.7243\n",
      "Epoch [2/50], Loss D: 0.5937, Loss G: 1.7705\n",
      "Epoch [2/50], Loss D: 0.6343, Loss G: 1.6805\n",
      "Epoch [2/50], Loss D: 0.6238, Loss G: 1.6758\n",
      "Epoch [2/50], Loss D: 0.6483, Loss G: 1.6986\n",
      "Epoch [2/50], Loss D: 0.6027, Loss G: 1.7423\n",
      "Epoch [2/50], Loss D: 0.5937, Loss G: 1.7525\n",
      "Epoch [2/50], Loss D: 0.5911, Loss G: 1.7244\n",
      "Epoch [2/50], Loss D: 0.5587, Loss G: 1.7418\n",
      "Epoch [2/50], Loss D: 0.5603, Loss G: 1.7190\n",
      "Epoch [2/50], Loss D: 0.5793, Loss G: 1.7264\n",
      "Epoch [2/50], Loss D: 0.5379, Loss G: 1.7909\n",
      "Epoch [2/50], Loss D: 0.5469, Loss G: 1.7544\n",
      "Epoch [2/50], Loss D: 0.5756, Loss G: 1.8174\n",
      "Epoch [2/50], Loss D: 0.5401, Loss G: 1.7733\n",
      "Epoch [2/50], Loss D: 0.5178, Loss G: 1.8219\n",
      "Epoch [2/50], Loss D: 0.4979, Loss G: 1.8261\n",
      "Epoch [2/50], Loss D: 0.4739, Loss G: 1.9034\n",
      "Epoch [2/50], Loss D: 0.4836, Loss G: 1.8352\n",
      "Epoch [2/50], Loss D: 0.4860, Loss G: 1.8492\n",
      "Epoch [2/50], Loss D: 0.4539, Loss G: 1.9401\n",
      "Epoch [2/50], Loss D: 0.4604, Loss G: 1.9409\n",
      "Epoch [2/50], Loss D: 0.4823, Loss G: 1.8853\n",
      "Epoch [2/50], Loss D: 0.4436, Loss G: 1.9072\n",
      "Epoch [2/50], Loss D: 0.4635, Loss G: 1.8676\n",
      "Epoch [2/50], Loss D: 0.4420, Loss G: 1.9275\n",
      "Epoch [2/50], Loss D: 0.4713, Loss G: 1.9401\n",
      "Epoch [2/50], Loss D: 0.4500, Loss G: 1.9518\n",
      "Epoch [2/50], Loss D: 0.4617, Loss G: 1.9370\n",
      "Epoch [2/50], Loss D: 0.4803, Loss G: 1.9083\n",
      "Epoch [2/50], Loss D: 0.4883, Loss G: 1.8809\n",
      "Epoch [2/50], Loss D: 0.4700, Loss G: 1.8580\n",
      "Epoch [2/50], Loss D: 0.4986, Loss G: 1.8422\n",
      "Epoch [2/50], Loss D: 0.5357, Loss G: 1.8354\n",
      "Epoch [2/50], Loss D: 0.5488, Loss G: 1.8289\n",
      "Epoch [2/50], Loss D: 0.5370, Loss G: 1.7887\n",
      "Epoch [2/50], Loss D: 0.5741, Loss G: 1.7626\n",
      "Epoch [2/50], Loss D: 0.5708, Loss G: 1.7863\n",
      "Epoch [2/50], Loss D: 0.5951, Loss G: 1.7822\n",
      "Epoch [2/50], Loss D: 0.6451, Loss G: 1.6784\n",
      "Epoch [2/50], Loss D: 0.6254, Loss G: 1.7307\n",
      "Epoch [2/50], Loss D: 0.6479, Loss G: 1.6329\n",
      "Epoch [2/50], Loss D: 0.6305, Loss G: 1.6921\n",
      "Epoch [2/50], Loss D: 0.6687, Loss G: 1.6679\n",
      "Epoch [2/50], Loss D: 0.6367, Loss G: 1.6845\n",
      "Epoch [2/50], Loss D: 0.6440, Loss G: 1.6058\n",
      "Epoch [2/50], Loss D: 0.6668, Loss G: 1.6795\n",
      "Epoch [2/50], Loss D: 0.6550, Loss G: 1.6407\n",
      "Epoch [2/50], Loss D: 0.6362, Loss G: 1.6902\n",
      "Epoch [2/50], Loss D: 0.6380, Loss G: 1.7344\n",
      "Epoch [2/50], Loss D: 0.5957, Loss G: 1.7709\n",
      "Epoch [2/50], Loss D: 0.6013, Loss G: 1.7950\n",
      "Epoch [2/50], Loss D: 0.5783, Loss G: 1.7872\n",
      "Epoch [2/50], Loss D: 0.5876, Loss G: 1.7995\n",
      "Epoch [2/50], Loss D: 0.6211, Loss G: 1.7447\n",
      "Epoch [2/50], Loss D: 0.5573, Loss G: 1.7826\n",
      "Epoch [2/50], Loss D: 0.5836, Loss G: 1.7439\n",
      "Epoch [2/50], Loss D: 0.6045, Loss G: 1.7366\n",
      "Epoch [2/50], Loss D: 0.5578, Loss G: 1.7892\n",
      "Epoch [2/50], Loss D: 0.5911, Loss G: 1.7857\n",
      "Epoch [2/50], Loss D: 0.5796, Loss G: 1.8297\n",
      "Epoch [2/50], Loss D: 0.5486, Loss G: 1.7996\n",
      "Epoch [2/50], Loss D: 0.5465, Loss G: 1.8339\n",
      "Epoch [2/50], Loss D: 0.5772, Loss G: 1.8168\n",
      "Epoch [2/50], Loss D: 0.5441, Loss G: 1.8358\n",
      "Epoch [2/50], Loss D: 0.5249, Loss G: 1.8448\n",
      "Epoch [2/50], Loss D: 0.5528, Loss G: 1.8376\n",
      "Epoch [2/50], Loss D: 0.5575, Loss G: 1.8106\n",
      "Epoch [2/50], Loss D: 0.5149, Loss G: 1.8554\n",
      "Epoch [2/50], Loss D: 0.4825, Loss G: 1.8371\n",
      "Epoch [2/50], Loss D: 0.5132, Loss G: 1.7744\n",
      "Epoch [2/50], Loss D: 0.4993, Loss G: 1.8325\n",
      "Epoch [2/50], Loss D: 0.5026, Loss G: 1.8581\n",
      "Epoch [2/50], Loss D: 0.4790, Loss G: 1.8948\n",
      "Epoch [2/50], Loss D: 0.4908, Loss G: 1.8743\n",
      "Epoch [2/50], Loss D: 0.5286, Loss G: 1.8484\n",
      "Epoch [2/50], Loss D: 0.5259, Loss G: 1.8076\n",
      "Epoch [2/50], Loss D: 0.5326, Loss G: 1.8256\n",
      "Epoch [2/50], Loss D: 0.5105, Loss G: 1.8461\n",
      "Epoch [2/50], Loss D: 0.5245, Loss G: 1.7996\n",
      "Epoch [2/50], Loss D: 0.5280, Loss G: 1.8663\n",
      "Epoch [2/50], Loss D: 0.5544, Loss G: 1.7891\n",
      "Epoch [2/50], Loss D: 0.5069, Loss G: 1.8282\n",
      "Epoch [2/50], Loss D: 0.4941, Loss G: 1.8216\n",
      "Epoch [2/50], Loss D: 0.4859, Loss G: 1.8027\n",
      "Epoch [2/50], Loss D: 0.5091, Loss G: 1.7927\n",
      "Epoch [2/50], Loss D: 0.5177, Loss G: 1.8002\n",
      "Epoch [2/50], Loss D: 0.4716, Loss G: 1.8385\n",
      "Epoch [2/50], Loss D: 0.4810, Loss G: 1.8108\n",
      "Epoch [2/50], Loss D: 0.4948, Loss G: 1.7642\n",
      "Epoch [2/50], Loss D: 0.5131, Loss G: 1.7917\n",
      "Epoch [2/50], Loss D: 0.4869, Loss G: 1.7747\n",
      "Epoch [2/50], Loss D: 0.5162, Loss G: 1.7939\n",
      "Epoch [2/50], Loss D: 0.4791, Loss G: 1.7791\n",
      "Epoch [2/50], Loss D: 0.5165, Loss G: 1.7242\n",
      "Epoch [2/50], Loss D: 0.5055, Loss G: 1.7435\n",
      "Epoch [2/50], Loss D: 0.5302, Loss G: 1.7120\n",
      "Epoch [2/50], Loss D: 0.5126, Loss G: 1.7658\n",
      "Epoch [2/50], Loss D: 0.5220, Loss G: 1.7629\n",
      "Epoch [2/50], Loss D: 0.5492, Loss G: 1.7636\n",
      "Epoch [2/50], Loss D: 0.5466, Loss G: 1.7296\n",
      "Epoch [2/50], Loss D: 0.5366, Loss G: 1.7910\n",
      "Epoch [2/50], Loss D: 0.4915, Loss G: 1.7990\n",
      "Epoch [2/50], Loss D: 0.5101, Loss G: 1.8059\n",
      "Epoch [2/50], Loss D: 0.4979, Loss G: 1.8348\n",
      "Epoch [2/50], Loss D: 0.5037, Loss G: 1.8409\n",
      "Epoch [2/50], Loss D: 0.5107, Loss G: 1.8079\n",
      "Epoch [2/50], Loss D: 0.5118, Loss G: 1.7534\n",
      "Epoch [2/50], Loss D: 0.5053, Loss G: 1.7269\n",
      "Epoch [2/50], Loss D: 0.4870, Loss G: 1.7821\n",
      "Epoch [2/50], Loss D: 0.5109, Loss G: 1.7290\n",
      "Epoch [2/50], Loss D: 0.5042, Loss G: 1.7608\n",
      "Epoch [2/50], Loss D: 0.4957, Loss G: 1.7817\n",
      "Epoch [2/50], Loss D: 0.4827, Loss G: 1.7892\n",
      "Epoch [2/50], Loss D: 0.4793, Loss G: 1.8648\n",
      "Epoch [2/50], Loss D: 0.4753, Loss G: 1.8578\n",
      "Epoch [2/50], Loss D: 0.4874, Loss G: 1.9203\n",
      "Epoch [2/50], Loss D: 0.4673, Loss G: 1.9432\n",
      "Epoch [2/50], Loss D: 0.4823, Loss G: 1.8797\n",
      "Epoch [2/50], Loss D: 0.4706, Loss G: 1.9156\n",
      "Epoch [2/50], Loss D: 0.4711, Loss G: 1.9287\n",
      "Epoch [2/50], Loss D: 0.4779, Loss G: 1.7921\n",
      "Epoch [2/50], Loss D: 0.4909, Loss G: 1.8637\n",
      "Epoch [2/50], Loss D: 0.4775, Loss G: 1.8173\n",
      "Epoch [2/50], Loss D: 0.4926, Loss G: 1.8098\n",
      "Epoch [2/50], Loss D: 0.4856, Loss G: 1.8003\n",
      "Epoch [2/50], Loss D: 0.5116, Loss G: 1.8158\n",
      "Epoch [2/50], Loss D: 0.4903, Loss G: 1.8033\n",
      "Epoch [2/50], Loss D: 0.4936, Loss G: 1.7878\n",
      "Epoch [2/50], Loss D: 0.5051, Loss G: 1.7377\n",
      "Epoch [2/50], Loss D: 0.5078, Loss G: 1.7734\n",
      "Epoch [2/50], Loss D: 0.5120, Loss G: 1.7652\n",
      "Epoch [2/50], Loss D: 0.5100, Loss G: 1.7254\n",
      "Epoch [2/50], Loss D: 0.5179, Loss G: 1.7495\n",
      "Epoch [2/50], Loss D: 0.5170, Loss G: 1.7757\n",
      "Epoch [2/50], Loss D: 0.5033, Loss G: 1.7631\n",
      "Epoch [2/50], Loss D: 0.5419, Loss G: 1.7399\n",
      "Epoch [2/50], Loss D: 0.5160, Loss G: 1.7492\n",
      "Epoch [2/50], Loss D: 0.4973, Loss G: 1.7434\n",
      "Epoch [2/50], Loss D: 0.5150, Loss G: 1.7138\n",
      "Epoch [2/50], Loss D: 0.5190, Loss G: 1.7386\n",
      "Epoch [2/50], Loss D: 0.4943, Loss G: 1.7319\n",
      "Epoch [2/50], Loss D: 0.5090, Loss G: 1.7872\n",
      "Epoch [2/50], Loss D: 0.4739, Loss G: 1.8151\n",
      "Epoch [2/50], Loss D: 0.5082, Loss G: 1.7496\n",
      "Epoch [2/50], Loss D: 0.4869, Loss G: 1.8223\n",
      "Epoch [2/50], Loss D: 0.4918, Loss G: 1.8985\n",
      "Epoch [2/50], Loss D: 0.4988, Loss G: 1.7995\n",
      "Epoch [2/50], Loss D: 0.4562, Loss G: 1.8719\n",
      "Epoch [2/50], Loss D: 0.4769, Loss G: 1.8248\n",
      "Epoch [2/50], Loss D: 0.4756, Loss G: 1.8218\n",
      "Epoch [2/50], Loss D: 0.4794, Loss G: 1.7914\n",
      "Epoch [2/50], Loss D: 0.4947, Loss G: 1.7155\n",
      "Epoch [2/50], Loss D: 0.5236, Loss G: 1.7458\n",
      "Epoch [2/50], Loss D: 0.5102, Loss G: 1.7817\n",
      "Epoch [2/50], Loss D: 0.5226, Loss G: 1.7433\n",
      "Epoch [2/50], Loss D: 0.5171, Loss G: 1.7450\n",
      "Epoch [2/50], Loss D: 0.5032, Loss G: 1.7842\n",
      "Epoch [2/50], Loss D: 0.5012, Loss G: 1.7900\n",
      "Epoch [2/50], Loss D: 0.5245, Loss G: 1.8020\n",
      "Epoch [2/50], Loss D: 0.5054, Loss G: 1.8323\n",
      "Epoch [2/50], Loss D: 0.4871, Loss G: 1.8685\n",
      "Epoch [2/50], Loss D: 0.4917, Loss G: 1.8999\n",
      "Epoch [2/50], Loss D: 0.4778, Loss G: 1.8963\n",
      "Epoch [2/50], Loss D: 0.4602, Loss G: 1.9071\n",
      "Epoch [2/50], Loss D: 0.4623, Loss G: 1.8471\n",
      "Epoch [2/50], Loss D: 0.4401, Loss G: 1.8893\n",
      "Epoch [2/50], Loss D: 0.4675, Loss G: 1.8326\n",
      "Epoch [2/50], Loss D: 0.4692, Loss G: 1.8323\n",
      "Epoch [2/50], Loss D: 0.4312, Loss G: 1.9622\n",
      "Epoch [2/50], Loss D: 0.4162, Loss G: 1.9919\n",
      "Epoch [2/50], Loss D: 0.4234, Loss G: 1.9496\n",
      "Epoch [2/50], Loss D: 0.4215, Loss G: 2.0026\n",
      "Epoch [2/50], Loss D: 0.3983, Loss G: 2.0712\n",
      "Epoch [2/50], Loss D: 0.4046, Loss G: 2.0494\n",
      "Epoch [2/50], Loss D: 0.3831, Loss G: 2.0195\n",
      "Epoch [2/50], Loss D: 0.3939, Loss G: 2.0284\n",
      "Epoch [2/50], Loss D: 0.3926, Loss G: 2.0730\n",
      "Epoch [2/50], Loss D: 0.4110, Loss G: 1.9986\n",
      "Epoch [2/50], Loss D: 0.3962, Loss G: 2.0255\n",
      "Epoch [2/50], Loss D: 0.3903, Loss G: 1.9753\n",
      "Epoch [2/50], Loss D: 0.4163, Loss G: 1.9881\n",
      "Epoch [2/50], Loss D: 0.4226, Loss G: 1.9399\n",
      "Epoch [2/50], Loss D: 0.4283, Loss G: 1.9019\n",
      "Epoch [2/50], Loss D: 0.4071, Loss G: 1.9324\n",
      "Epoch [2/50], Loss D: 0.4377, Loss G: 1.8578\n",
      "Epoch [2/50], Loss D: 0.4355, Loss G: 1.9108\n",
      "Epoch [2/50], Loss D: 0.4318, Loss G: 1.9294\n",
      "Epoch [2/50], Loss D: 0.4704, Loss G: 1.8796\n",
      "Epoch [2/50], Loss D: 0.4516, Loss G: 1.8919\n",
      "Epoch [2/50], Loss D: 0.4613, Loss G: 1.9466\n",
      "Epoch [2/50], Loss D: 0.4839, Loss G: 1.9020\n",
      "Epoch [2/50], Loss D: 0.5009, Loss G: 1.8594\n",
      "Epoch [2/50], Loss D: 0.4821, Loss G: 1.9072\n",
      "Epoch [2/50], Loss D: 0.5080, Loss G: 1.8435\n",
      "Epoch [2/50], Loss D: 0.4962, Loss G: 1.8644\n",
      "Epoch [2/50], Loss D: 0.4682, Loss G: 1.9086\n",
      "Epoch [2/50], Loss D: 0.4730, Loss G: 1.9214\n",
      "Epoch [2/50], Loss D: 0.5004, Loss G: 1.8579\n",
      "Epoch [2/50], Loss D: 0.4896, Loss G: 1.8920\n",
      "Epoch [2/50], Loss D: 0.4806, Loss G: 1.8879\n",
      "Epoch [2/50], Loss D: 0.4506, Loss G: 1.9527\n",
      "Epoch [2/50], Loss D: 0.4592, Loss G: 1.9608\n",
      "Epoch [2/50], Loss D: 0.4253, Loss G: 1.9924\n",
      "Epoch [2/50], Loss D: 0.4311, Loss G: 1.9974\n",
      "Epoch [2/50], Loss D: 0.4364, Loss G: 1.9701\n",
      "Epoch [2/50], Loss D: 0.4234, Loss G: 1.9984\n",
      "Epoch [2/50], Loss D: 0.4271, Loss G: 1.9107\n",
      "Epoch [2/50], Loss D: 0.4161, Loss G: 2.0005\n",
      "Epoch [2/50], Loss D: 0.4261, Loss G: 1.9321\n",
      "Epoch [2/50], Loss D: 0.4240, Loss G: 1.9713\n",
      "Epoch [2/50], Loss D: 0.4248, Loss G: 1.9971\n",
      "Epoch [2/50], Loss D: 0.4295, Loss G: 1.9242\n",
      "Epoch [2/50], Loss D: 0.4143, Loss G: 1.9123\n",
      "Epoch [2/50], Loss D: 0.4224, Loss G: 1.9455\n",
      "Epoch [2/50], Loss D: 0.4040, Loss G: 1.9415\n",
      "Epoch [2/50], Loss D: 0.4040, Loss G: 1.9619\n",
      "Epoch [2/50], Loss D: 0.4061, Loss G: 2.0316\n",
      "Epoch [2/50], Loss D: 0.4317, Loss G: 2.0019\n",
      "Epoch [2/50], Loss D: 0.4247, Loss G: 1.9077\n",
      "Epoch [2/50], Loss D: 0.4238, Loss G: 1.9912\n",
      "Epoch [2/50], Loss D: 0.4325, Loss G: 1.9823\n",
      "Epoch [2/50], Loss D: 0.4310, Loss G: 1.9621\n",
      "Epoch [2/50], Loss D: 0.4301, Loss G: 1.9289\n",
      "Epoch [2/50], Loss D: 0.4568, Loss G: 1.9875\n",
      "Epoch [2/50], Loss D: 0.4494, Loss G: 1.9058\n",
      "Epoch [2/50], Loss D: 0.4932, Loss G: 1.7595\n",
      "Epoch [2/50], Loss D: 0.4932, Loss G: 1.8997\n",
      "Epoch [2/50], Loss D: 0.4748, Loss G: 1.8199\n",
      "Epoch [2/50], Loss D: 0.4715, Loss G: 1.8565\n",
      "Epoch [2/50], Loss D: 0.4883, Loss G: 1.8611\n",
      "Epoch [2/50], Loss D: 0.4823, Loss G: 1.8518\n",
      "Epoch [2/50], Loss D: 0.5296, Loss G: 1.7922\n",
      "Epoch [2/50], Loss D: 0.4621, Loss G: 1.9310\n",
      "Epoch [2/50], Loss D: 0.5149, Loss G: 1.8239\n",
      "Epoch [2/50], Loss D: 0.5248, Loss G: 1.7782\n",
      "Epoch [2/50], Loss D: 0.5340, Loss G: 1.7073\n",
      "Epoch [2/50], Loss D: 0.5317, Loss G: 1.7041\n",
      "Epoch [2/50], Loss D: 0.5257, Loss G: 1.7016\n",
      "Epoch [2/50], Loss D: 0.5485, Loss G: 1.6667\n",
      "Epoch [2/50], Loss D: 0.5421, Loss G: 1.7366\n",
      "Epoch [2/50], Loss D: 0.5426, Loss G: 1.8417\n",
      "Epoch [2/50], Loss D: 0.5926, Loss G: 1.7230\n",
      "Epoch [2/50], Loss D: 0.5569, Loss G: 1.7382\n",
      "Epoch [2/50], Loss D: 0.5476, Loss G: 1.7058\n",
      "Epoch [2/50], Loss D: 0.5694, Loss G: 1.6481\n",
      "Epoch [2/50], Loss D: 0.5359, Loss G: 1.7559\n",
      "Epoch [2/50], Loss D: 0.5407, Loss G: 1.7085\n",
      "Epoch [2/50], Loss D: 0.5581, Loss G: 1.6688\n",
      "Epoch [2/50], Loss D: 0.5302, Loss G: 1.7697\n",
      "Epoch [2/50], Loss D: 0.5481, Loss G: 1.8009\n",
      "Epoch [2/50], Loss D: 0.5633, Loss G: 1.8210\n",
      "Epoch [2/50], Loss D: 0.5511, Loss G: 1.8484\n",
      "Epoch [2/50], Loss D: 0.5293, Loss G: 1.8392\n",
      "Epoch [2/50], Loss D: 0.5072, Loss G: 1.8268\n",
      "Epoch [2/50], Loss D: 0.5223, Loss G: 1.8606\n",
      "Epoch [2/50], Loss D: 0.5165, Loss G: 1.8574\n",
      "Epoch [2/50], Loss D: 0.4973, Loss G: 1.7882\n",
      "Epoch [2/50], Loss D: 0.4777, Loss G: 1.8119\n",
      "Epoch [2/50], Loss D: 0.4817, Loss G: 1.7451\n",
      "Epoch [2/50], Loss D: 0.4519, Loss G: 1.8579\n",
      "Epoch [2/50], Loss D: 0.4404, Loss G: 1.8374\n",
      "Epoch [2/50], Loss D: 0.4346, Loss G: 1.8494\n",
      "Epoch [2/50], Loss D: 0.4520, Loss G: 1.9083\n",
      "Epoch [2/50], Loss D: 0.4202, Loss G: 1.9186\n",
      "Epoch [2/50], Loss D: 0.4360, Loss G: 1.9838\n",
      "Epoch [2/50], Loss D: 0.4303, Loss G: 1.9568\n",
      "Epoch [2/50], Loss D: 0.4060, Loss G: 1.9402\n",
      "Epoch [2/50], Loss D: 0.4323, Loss G: 1.9629\n",
      "Epoch [2/50], Loss D: 0.4372, Loss G: 1.8967\n",
      "Epoch [2/50], Loss D: 0.4259, Loss G: 1.8436\n",
      "Epoch [2/50], Loss D: 0.4411, Loss G: 1.9128\n",
      "Epoch [2/50], Loss D: 0.4149, Loss G: 1.9374\n",
      "Epoch [2/50], Loss D: 0.4168, Loss G: 1.9246\n",
      "Epoch [3/50], Loss D: 0.4652, Loss G: 1.8301\n",
      "Epoch [3/50], Loss D: 0.4322, Loss G: 1.9242\n",
      "Epoch [3/50], Loss D: 0.4563, Loss G: 1.8960\n",
      "Epoch [3/50], Loss D: 0.4589, Loss G: 1.9234\n",
      "Epoch [3/50], Loss D: 0.4697, Loss G: 1.9475\n",
      "Epoch [3/50], Loss D: 0.4857, Loss G: 1.8750\n",
      "Epoch [3/50], Loss D: 0.4796, Loss G: 1.8600\n",
      "Epoch [3/50], Loss D: 0.5104, Loss G: 1.8341\n",
      "Epoch [3/50], Loss D: 0.5339, Loss G: 1.8077\n",
      "Epoch [3/50], Loss D: 0.5429, Loss G: 1.7612\n",
      "Epoch [3/50], Loss D: 0.5274, Loss G: 1.7369\n",
      "Epoch [3/50], Loss D: 0.5579, Loss G: 1.7274\n",
      "Epoch [3/50], Loss D: 0.5159, Loss G: 1.8144\n",
      "Epoch [3/50], Loss D: 0.5911, Loss G: 1.7569\n",
      "Epoch [3/50], Loss D: 0.5894, Loss G: 1.7067\n",
      "Epoch [3/50], Loss D: 0.5570, Loss G: 1.7222\n",
      "Epoch [3/50], Loss D: 0.5709, Loss G: 1.7593\n",
      "Epoch [3/50], Loss D: 0.5834, Loss G: 1.7429\n",
      "Epoch [3/50], Loss D: 0.5626, Loss G: 1.7325\n",
      "Epoch [3/50], Loss D: 0.5421, Loss G: 1.7661\n",
      "Epoch [3/50], Loss D: 0.5748, Loss G: 1.7391\n",
      "Epoch [3/50], Loss D: 0.5281, Loss G: 1.7994\n",
      "Epoch [3/50], Loss D: 0.5688, Loss G: 1.6932\n",
      "Epoch [3/50], Loss D: 0.5220, Loss G: 1.7907\n",
      "Epoch [3/50], Loss D: 0.5551, Loss G: 1.7287\n",
      "Epoch [3/50], Loss D: 0.5204, Loss G: 1.7641\n",
      "Epoch [3/50], Loss D: 0.4932, Loss G: 1.7726\n",
      "Epoch [3/50], Loss D: 0.5280, Loss G: 1.7805\n",
      "Epoch [3/50], Loss D: 0.4919, Loss G: 1.8259\n",
      "Epoch [3/50], Loss D: 0.4876, Loss G: 1.8227\n",
      "Epoch [3/50], Loss D: 0.5014, Loss G: 1.8779\n",
      "Epoch [3/50], Loss D: 0.4885, Loss G: 1.8875\n",
      "Epoch [3/50], Loss D: 0.5158, Loss G: 1.7907\n",
      "Epoch [3/50], Loss D: 0.4842, Loss G: 1.7863\n",
      "Epoch [3/50], Loss D: 0.5127, Loss G: 1.7599\n",
      "Epoch [3/50], Loss D: 0.5222, Loss G: 1.7031\n",
      "Epoch [3/50], Loss D: 0.5204, Loss G: 1.6521\n",
      "Epoch [3/50], Loss D: 0.4737, Loss G: 1.6768\n",
      "Epoch [3/50], Loss D: 0.5125, Loss G: 1.7396\n",
      "Epoch [3/50], Loss D: 0.4968, Loss G: 1.7438\n",
      "Epoch [3/50], Loss D: 0.5231, Loss G: 1.7843\n",
      "Epoch [3/50], Loss D: 0.5231, Loss G: 1.7739\n",
      "Epoch [3/50], Loss D: 0.5113, Loss G: 1.7889\n",
      "Epoch [3/50], Loss D: 0.4919, Loss G: 1.8582\n",
      "Epoch [3/50], Loss D: 0.4964, Loss G: 1.7808\n",
      "Epoch [3/50], Loss D: 0.4939, Loss G: 1.7882\n",
      "Epoch [3/50], Loss D: 0.4696, Loss G: 1.8244\n",
      "Epoch [3/50], Loss D: 0.4489, Loss G: 1.8362\n",
      "Epoch [3/50], Loss D: 0.4768, Loss G: 1.8172\n",
      "Epoch [3/50], Loss D: 0.5043, Loss G: 1.8470\n",
      "Epoch [3/50], Loss D: 0.4696, Loss G: 1.8901\n",
      "Epoch [3/50], Loss D: 0.4516, Loss G: 1.8771\n",
      "Epoch [3/50], Loss D: 0.4573, Loss G: 1.8978\n",
      "Epoch [3/50], Loss D: 0.4265, Loss G: 1.9467\n",
      "Epoch [3/50], Loss D: 0.4483, Loss G: 1.9639\n",
      "Epoch [3/50], Loss D: 0.4120, Loss G: 2.0234\n",
      "Epoch [3/50], Loss D: 0.3993, Loss G: 2.0648\n",
      "Epoch [3/50], Loss D: 0.3954, Loss G: 2.0385\n",
      "Epoch [3/50], Loss D: 0.4127, Loss G: 1.9960\n",
      "Epoch [3/50], Loss D: 0.3942, Loss G: 1.9949\n",
      "Epoch [3/50], Loss D: 0.3872, Loss G: 2.0356\n",
      "Epoch [3/50], Loss D: 0.4048, Loss G: 1.9927\n",
      "Epoch [3/50], Loss D: 0.3747, Loss G: 1.9656\n",
      "Epoch [3/50], Loss D: 0.3881, Loss G: 1.9823\n",
      "Epoch [3/50], Loss D: 0.3809, Loss G: 2.0039\n",
      "Epoch [3/50], Loss D: 0.4007, Loss G: 2.0049\n",
      "Epoch [3/50], Loss D: 0.3729, Loss G: 2.0293\n",
      "Epoch [3/50], Loss D: 0.3753, Loss G: 2.0799\n",
      "Epoch [3/50], Loss D: 0.3838, Loss G: 2.0714\n",
      "Epoch [3/50], Loss D: 0.3722, Loss G: 2.0843\n",
      "Epoch [3/50], Loss D: 0.4098, Loss G: 2.0198\n",
      "Epoch [3/50], Loss D: 0.3814, Loss G: 2.0384\n",
      "Epoch [3/50], Loss D: 0.4160, Loss G: 1.9219\n",
      "Epoch [3/50], Loss D: 0.4236, Loss G: 1.9068\n",
      "Epoch [3/50], Loss D: 0.4267, Loss G: 1.9037\n",
      "Epoch [3/50], Loss D: 0.4446, Loss G: 1.9108\n",
      "Epoch [3/50], Loss D: 0.4394, Loss G: 1.9788\n",
      "Epoch [3/50], Loss D: 0.4513, Loss G: 1.9321\n",
      "Epoch [3/50], Loss D: 0.4539, Loss G: 1.9346\n",
      "Epoch [3/50], Loss D: 0.4332, Loss G: 1.9789\n",
      "Epoch [3/50], Loss D: 0.4761, Loss G: 1.9246\n",
      "Epoch [3/50], Loss D: 0.4950, Loss G: 1.8897\n",
      "Epoch [3/50], Loss D: 0.4915, Loss G: 1.8752\n",
      "Epoch [3/50], Loss D: 0.4840, Loss G: 1.8665\n",
      "Epoch [3/50], Loss D: 0.5106, Loss G: 1.8108\n",
      "Epoch [3/50], Loss D: 0.4659, Loss G: 1.8515\n",
      "Epoch [3/50], Loss D: 0.5160, Loss G: 1.8327\n",
      "Epoch [3/50], Loss D: 0.4924, Loss G: 1.8881\n",
      "Epoch [3/50], Loss D: 0.5140, Loss G: 1.8304\n",
      "Epoch [3/50], Loss D: 0.4799, Loss G: 1.9156\n",
      "Epoch [3/50], Loss D: 0.4749, Loss G: 1.9433\n",
      "Epoch [3/50], Loss D: 0.4954, Loss G: 1.8663\n",
      "Epoch [3/50], Loss D: 0.4865, Loss G: 1.7915\n",
      "Epoch [3/50], Loss D: 0.4822, Loss G: 1.8627\n",
      "Epoch [3/50], Loss D: 0.4623, Loss G: 1.8812\n",
      "Epoch [3/50], Loss D: 0.4638, Loss G: 1.9830\n",
      "Epoch [3/50], Loss D: 0.4565, Loss G: 1.9598\n",
      "Epoch [3/50], Loss D: 0.4254, Loss G: 1.9186\n",
      "Epoch [3/50], Loss D: 0.4175, Loss G: 1.9292\n",
      "Epoch [3/50], Loss D: 0.3913, Loss G: 2.0296\n",
      "Epoch [3/50], Loss D: 0.4017, Loss G: 1.9989\n",
      "Epoch [3/50], Loss D: 0.4210, Loss G: 1.9810\n",
      "Epoch [3/50], Loss D: 0.4168, Loss G: 2.0034\n",
      "Epoch [3/50], Loss D: 0.4047, Loss G: 2.0557\n",
      "Epoch [3/50], Loss D: 0.4205, Loss G: 1.9722\n",
      "Epoch [3/50], Loss D: 0.3851, Loss G: 1.9961\n",
      "Epoch [3/50], Loss D: 0.3884, Loss G: 2.0100\n",
      "Epoch [3/50], Loss D: 0.4331, Loss G: 1.9158\n",
      "Epoch [3/50], Loss D: 0.3955, Loss G: 1.9414\n",
      "Epoch [3/50], Loss D: 0.3998, Loss G: 2.0102\n",
      "Epoch [3/50], Loss D: 0.3846, Loss G: 2.0843\n",
      "Epoch [3/50], Loss D: 0.4139, Loss G: 2.0650\n",
      "Epoch [3/50], Loss D: 0.3912, Loss G: 2.0493\n",
      "Epoch [3/50], Loss D: 0.4065, Loss G: 2.0868\n",
      "Epoch [3/50], Loss D: 0.3918, Loss G: 2.0031\n",
      "Epoch [3/50], Loss D: 0.4054, Loss G: 1.9996\n",
      "Epoch [3/50], Loss D: 0.3858, Loss G: 2.0081\n",
      "Epoch [3/50], Loss D: 0.4084, Loss G: 2.0032\n",
      "Epoch [3/50], Loss D: 0.4104, Loss G: 1.9814\n",
      "Epoch [3/50], Loss D: 0.3930, Loss G: 2.1228\n",
      "Epoch [3/50], Loss D: 0.4039, Loss G: 2.0431\n",
      "Epoch [3/50], Loss D: 0.4090, Loss G: 1.9349\n",
      "Epoch [3/50], Loss D: 0.4355, Loss G: 1.8573\n",
      "Epoch [3/50], Loss D: 0.4145, Loss G: 1.8870\n",
      "Epoch [3/50], Loss D: 0.4335, Loss G: 1.8898\n",
      "Epoch [3/50], Loss D: 0.4295, Loss G: 1.8771\n",
      "Epoch [3/50], Loss D: 0.4379, Loss G: 1.9533\n",
      "Epoch [3/50], Loss D: 0.4201, Loss G: 1.9503\n",
      "Epoch [3/50], Loss D: 0.4113, Loss G: 1.9557\n",
      "Epoch [3/50], Loss D: 0.4449, Loss G: 1.9292\n",
      "Epoch [3/50], Loss D: 0.4325, Loss G: 1.9377\n",
      "Epoch [3/50], Loss D: 0.4235, Loss G: 1.9116\n",
      "Epoch [3/50], Loss D: 0.4347, Loss G: 1.8558\n",
      "Epoch [3/50], Loss D: 0.4624, Loss G: 1.8276\n",
      "Epoch [3/50], Loss D: 0.4638, Loss G: 1.7563\n",
      "Epoch [3/50], Loss D: 0.4360, Loss G: 1.8128\n",
      "Epoch [3/50], Loss D: 0.4662, Loss G: 1.7958\n",
      "Epoch [3/50], Loss D: 0.4760, Loss G: 1.7560\n",
      "Epoch [3/50], Loss D: 0.4668, Loss G: 1.8393\n",
      "Epoch [3/50], Loss D: 0.4669, Loss G: 1.8153\n",
      "Epoch [3/50], Loss D: 0.4809, Loss G: 1.7984\n",
      "Epoch [3/50], Loss D: 0.4626, Loss G: 1.8642\n",
      "Epoch [3/50], Loss D: 0.4745, Loss G: 1.8231\n",
      "Epoch [3/50], Loss D: 0.4765, Loss G: 1.7634\n",
      "Epoch [3/50], Loss D: 0.4596, Loss G: 1.7896\n",
      "Epoch [3/50], Loss D: 0.4772, Loss G: 1.7275\n",
      "Epoch [3/50], Loss D: 0.4380, Loss G: 1.8065\n",
      "Epoch [3/50], Loss D: 0.4845, Loss G: 1.7731\n",
      "Epoch [3/50], Loss D: 0.4561, Loss G: 1.8438\n",
      "Epoch [3/50], Loss D: 0.4585, Loss G: 1.8145\n",
      "Epoch [3/50], Loss D: 0.4356, Loss G: 1.8588\n",
      "Epoch [3/50], Loss D: 0.4346, Loss G: 1.9032\n",
      "Epoch [3/50], Loss D: 0.4173, Loss G: 1.9371\n",
      "Epoch [3/50], Loss D: 0.4263, Loss G: 1.9701\n",
      "Epoch [3/50], Loss D: 0.3944, Loss G: 2.0413\n",
      "Epoch [3/50], Loss D: 0.4105, Loss G: 1.9270\n",
      "Epoch [3/50], Loss D: 0.4144, Loss G: 1.8758\n",
      "Epoch [3/50], Loss D: 0.4300, Loss G: 1.8654\n",
      "Epoch [3/50], Loss D: 0.3920, Loss G: 1.9462\n",
      "Epoch [3/50], Loss D: 0.4361, Loss G: 1.8400\n",
      "Epoch [3/50], Loss D: 0.4387, Loss G: 1.9078\n",
      "Epoch [3/50], Loss D: 0.4081, Loss G: 1.9212\n",
      "Epoch [3/50], Loss D: 0.4185, Loss G: 1.9632\n",
      "Epoch [3/50], Loss D: 0.4416, Loss G: 1.9626\n",
      "Epoch [3/50], Loss D: 0.4218, Loss G: 1.9649\n",
      "Epoch [3/50], Loss D: 0.4011, Loss G: 1.9946\n",
      "Epoch [3/50], Loss D: 0.4218, Loss G: 1.9151\n",
      "Epoch [3/50], Loss D: 0.4442, Loss G: 1.9258\n",
      "Epoch [3/50], Loss D: 0.3935, Loss G: 2.0066\n",
      "Epoch [3/50], Loss D: 0.4111, Loss G: 2.0076\n",
      "Epoch [3/50], Loss D: 0.4108, Loss G: 1.9898\n",
      "Epoch [3/50], Loss D: 0.3952, Loss G: 2.0042\n",
      "Epoch [3/50], Loss D: 0.4032, Loss G: 2.0051\n",
      "Epoch [3/50], Loss D: 0.3854, Loss G: 1.9623\n",
      "Epoch [3/50], Loss D: 0.4045, Loss G: 1.9966\n",
      "Epoch [3/50], Loss D: 0.3804, Loss G: 2.0456\n",
      "Epoch [3/50], Loss D: 0.4036, Loss G: 2.0076\n",
      "Epoch [3/50], Loss D: 0.3737, Loss G: 2.0939\n",
      "Epoch [3/50], Loss D: 0.4040, Loss G: 2.0524\n",
      "Epoch [3/50], Loss D: 0.4195, Loss G: 1.9912\n",
      "Epoch [3/50], Loss D: 0.4198, Loss G: 1.8874\n",
      "Epoch [3/50], Loss D: 0.4213, Loss G: 1.8423\n",
      "Epoch [3/50], Loss D: 0.3945, Loss G: 1.9006\n",
      "Epoch [3/50], Loss D: 0.4014, Loss G: 1.9503\n",
      "Epoch [3/50], Loss D: 0.4003, Loss G: 2.0006\n",
      "Epoch [3/50], Loss D: 0.3843, Loss G: 2.1297\n",
      "Epoch [3/50], Loss D: 0.3900, Loss G: 2.0820\n",
      "Epoch [3/50], Loss D: 0.3726, Loss G: 2.0165\n",
      "Epoch [3/50], Loss D: 0.4012, Loss G: 1.9008\n",
      "Epoch [3/50], Loss D: 0.4005, Loss G: 1.9741\n",
      "Epoch [3/50], Loss D: 0.3848, Loss G: 2.0306\n",
      "Epoch [3/50], Loss D: 0.3984, Loss G: 1.9613\n",
      "Epoch [3/50], Loss D: 0.3990, Loss G: 1.9358\n",
      "Epoch [3/50], Loss D: 0.4141, Loss G: 1.9299\n",
      "Epoch [3/50], Loss D: 0.4203, Loss G: 1.8828\n",
      "Epoch [3/50], Loss D: 0.4021, Loss G: 1.9081\n",
      "Epoch [3/50], Loss D: 0.4242, Loss G: 1.9025\n",
      "Epoch [3/50], Loss D: 0.3930, Loss G: 1.9220\n",
      "Epoch [3/50], Loss D: 0.4135, Loss G: 1.9872\n",
      "Epoch [3/50], Loss D: 0.4140, Loss G: 2.0070\n",
      "Epoch [3/50], Loss D: 0.4351, Loss G: 1.9720\n",
      "Epoch [3/50], Loss D: 0.4272, Loss G: 1.9611\n",
      "Epoch [3/50], Loss D: 0.4393, Loss G: 1.8349\n",
      "Epoch [3/50], Loss D: 0.4358, Loss G: 1.7940\n",
      "Epoch [3/50], Loss D: 0.4261, Loss G: 1.8432\n",
      "Epoch [3/50], Loss D: 0.4242, Loss G: 1.7883\n",
      "Epoch [3/50], Loss D: 0.4337, Loss G: 1.8371\n",
      "Epoch [3/50], Loss D: 0.4437, Loss G: 1.8365\n",
      "Epoch [3/50], Loss D: 0.4485, Loss G: 2.0061\n",
      "Epoch [3/50], Loss D: 0.4421, Loss G: 1.9217\n",
      "Epoch [3/50], Loss D: 0.4342, Loss G: 1.9903\n",
      "Epoch [3/50], Loss D: 0.4634, Loss G: 1.8148\n",
      "Epoch [3/50], Loss D: 0.4640, Loss G: 1.8182\n",
      "Epoch [3/50], Loss D: 0.4625, Loss G: 1.7166\n",
      "Epoch [3/50], Loss D: 0.4762, Loss G: 1.7291\n",
      "Epoch [3/50], Loss D: 0.4352, Loss G: 1.8230\n",
      "Epoch [3/50], Loss D: 0.4597, Loss G: 1.8285\n",
      "Epoch [3/50], Loss D: 0.4260, Loss G: 1.9037\n",
      "Epoch [3/50], Loss D: 0.4802, Loss G: 1.8487\n",
      "Epoch [3/50], Loss D: 0.4585, Loss G: 1.9469\n",
      "Epoch [3/50], Loss D: 0.4605, Loss G: 1.9626\n",
      "Epoch [3/50], Loss D: 0.4499, Loss G: 2.0018\n",
      "Epoch [3/50], Loss D: 0.4602, Loss G: 1.8709\n",
      "Epoch [3/50], Loss D: 0.4335, Loss G: 1.9065\n",
      "Epoch [3/50], Loss D: 0.4494, Loss G: 1.8035\n",
      "Epoch [3/50], Loss D: 0.4281, Loss G: 1.8115\n",
      "Epoch [3/50], Loss D: 0.4358, Loss G: 1.8407\n",
      "Epoch [3/50], Loss D: 0.4297, Loss G: 1.9096\n",
      "Epoch [3/50], Loss D: 0.4281, Loss G: 1.9862\n",
      "Epoch [3/50], Loss D: 0.4160, Loss G: 2.0831\n",
      "Epoch [3/50], Loss D: 0.4280, Loss G: 2.0341\n",
      "Epoch [3/50], Loss D: 0.4221, Loss G: 2.0510\n",
      "Epoch [3/50], Loss D: 0.3834, Loss G: 2.0254\n",
      "Epoch [3/50], Loss D: 0.4051, Loss G: 2.0007\n",
      "Epoch [3/50], Loss D: 0.3980, Loss G: 1.9570\n",
      "Epoch [3/50], Loss D: 0.3996, Loss G: 1.9300\n",
      "Epoch [3/50], Loss D: 0.3840, Loss G: 1.9076\n",
      "Epoch [3/50], Loss D: 0.3846, Loss G: 1.8908\n",
      "Epoch [3/50], Loss D: 0.4050, Loss G: 1.8917\n",
      "Epoch [3/50], Loss D: 0.3931, Loss G: 1.9394\n",
      "Epoch [3/50], Loss D: 0.3764, Loss G: 2.0514\n",
      "Epoch [3/50], Loss D: 0.4219, Loss G: 2.0155\n",
      "Epoch [3/50], Loss D: 0.3760, Loss G: 2.1318\n",
      "Epoch [3/50], Loss D: 0.3719, Loss G: 2.0614\n",
      "Epoch [3/50], Loss D: 0.4001, Loss G: 1.9968\n",
      "Epoch [3/50], Loss D: 0.3734, Loss G: 2.0250\n",
      "Epoch [3/50], Loss D: 0.4052, Loss G: 1.8514\n",
      "Epoch [3/50], Loss D: 0.3742, Loss G: 1.8914\n",
      "Epoch [3/50], Loss D: 0.3950, Loss G: 1.8765\n",
      "Epoch [3/50], Loss D: 0.3834, Loss G: 1.9025\n",
      "Epoch [3/50], Loss D: 0.3980, Loss G: 1.9075\n",
      "Epoch [3/50], Loss D: 0.3830, Loss G: 2.0522\n",
      "Epoch [3/50], Loss D: 0.3870, Loss G: 2.0430\n",
      "Epoch [3/50], Loss D: 0.3625, Loss G: 2.0135\n",
      "Epoch [3/50], Loss D: 0.3353, Loss G: 2.1032\n",
      "Epoch [3/50], Loss D: 0.3655, Loss G: 1.9956\n",
      "Epoch [3/50], Loss D: 0.3729, Loss G: 2.0393\n",
      "Epoch [3/50], Loss D: 0.3681, Loss G: 2.0317\n",
      "Epoch [3/50], Loss D: 0.3674, Loss G: 1.9700\n",
      "Epoch [3/50], Loss D: 0.3571, Loss G: 2.0444\n",
      "Epoch [3/50], Loss D: 0.3901, Loss G: 1.9008\n",
      "Epoch [3/50], Loss D: 0.3807, Loss G: 1.9710\n",
      "Epoch [3/50], Loss D: 0.3493, Loss G: 2.0127\n",
      "Epoch [3/50], Loss D: 0.3690, Loss G: 1.9616\n",
      "Epoch [3/50], Loss D: 0.3715, Loss G: 1.9511\n",
      "Epoch [3/50], Loss D: 0.3742, Loss G: 2.0240\n",
      "Epoch [3/50], Loss D: 0.3843, Loss G: 2.0433\n",
      "Epoch [3/50], Loss D: 0.3653, Loss G: 2.0346\n",
      "Epoch [3/50], Loss D: 0.3813, Loss G: 2.0129\n",
      "Epoch [3/50], Loss D: 0.4156, Loss G: 1.9115\n",
      "Epoch [3/50], Loss D: 0.3884, Loss G: 1.8876\n",
      "Epoch [3/50], Loss D: 0.4018, Loss G: 1.8175\n",
      "Epoch [3/50], Loss D: 0.3934, Loss G: 1.8332\n",
      "Epoch [3/50], Loss D: 0.3975, Loss G: 1.9225\n",
      "Epoch [3/50], Loss D: 0.3771, Loss G: 2.0224\n",
      "Epoch [3/50], Loss D: 0.4278, Loss G: 1.9760\n",
      "Epoch [3/50], Loss D: 0.3781, Loss G: 2.0397\n",
      "Epoch [3/50], Loss D: 0.4183, Loss G: 2.0240\n",
      "Epoch [3/50], Loss D: 0.4286, Loss G: 1.9517\n",
      "Epoch [3/50], Loss D: 0.4374, Loss G: 1.8943\n",
      "Epoch [3/50], Loss D: 0.4403, Loss G: 1.8118\n",
      "Epoch [3/50], Loss D: 0.4104, Loss G: 1.8951\n",
      "Epoch [3/50], Loss D: 0.4278, Loss G: 1.8611\n",
      "Epoch [3/50], Loss D: 0.4511, Loss G: 1.8504\n",
      "Epoch [3/50], Loss D: 0.4515, Loss G: 1.8393\n",
      "Epoch [3/50], Loss D: 0.4490, Loss G: 1.8815\n",
      "Epoch [3/50], Loss D: 0.4859, Loss G: 1.7961\n",
      "Epoch [3/50], Loss D: 0.4698, Loss G: 1.8263\n",
      "Epoch [3/50], Loss D: 0.4393, Loss G: 1.8431\n",
      "Epoch [3/50], Loss D: 0.4745, Loss G: 1.7796\n",
      "Epoch [3/50], Loss D: 0.4470, Loss G: 1.8624\n",
      "Epoch [3/50], Loss D: 0.4505, Loss G: 1.8658\n",
      "Epoch [3/50], Loss D: 0.4451, Loss G: 1.9453\n",
      "Epoch [3/50], Loss D: 0.4419, Loss G: 1.9067\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m outputs \u001b[38;5;241m=\u001b[39m D(fake_images)                \u001b[38;5;66;03m# Try to fool D with fake images\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loss_G \u001b[38;5;241m=\u001b[39m criterion(outputs, real_labels)  \u001b[38;5;66;03m# G wants D to label them as real (1)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m loss_G\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     38\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss D: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_D\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss G: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_G\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ipykernel_py3/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "#Loop over each batch and epoch.\n",
    "#_ ignores the labels since GANs are unsupervised.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for real_images, _ in dataloader:\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # Real and fake labels\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train on real images\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs_real = D(real_images)           # Real image score\n",
    "        loss_real = criterion(outputs_real, real_labels)\n",
    "\n",
    "        # Generate fake images\n",
    "        # z = torch.randn(batch_size, noise_dim).to(device)\n",
    "        z = torch.randn(batch_size, noise_dim, 1, 1).to(device)\n",
    "        fake_images = G(z)\n",
    "\n",
    "        outputs_fake = D(fake_images.detach())  # Detach to avoid updating G\n",
    "        loss_fake = criterion(outputs_fake, fake_labels)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        outputs = D(fake_images)                # Try to fool D with fake images\n",
    "        loss_G = criterion(outputs, real_labels)  # G wants D to label them as real (1)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "          with torch.no_grad():  # Turn off gradients for inference\n",
    "            z = torch.randn(64, noise_dim).to(device)\n",
    "            fake = G(z).cpu()\n",
    "            grid = fake.view(64, 1, 28, 28).detach().numpy()\n",
    "\n",
    "            # Create a 8x8 grid of images\n",
    "            fig, axs = plt.subplots(8, 8, figsize=(8, 8))\n",
    "            for i in range(8):\n",
    "                for j in range(8):\n",
    "                    axs[i, j].imshow(grid[i*8+j][0], cmap='gray')\n",
    "                    axs[i, j].axis('off')\n",
    "            plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce7fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel_py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
