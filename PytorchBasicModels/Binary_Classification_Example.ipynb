{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Binary Classification using ANN in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_OV_TJzIvyIs"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.2.2'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTf32UH0v3Dx",
        "outputId": "a054e17a-5ec5-47b3-9b01-2a4357658159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_ZkuQB4Vv3ci"
      },
      "outputs": [],
      "source": [
        "# Load the dataset (assuming the same CSV file is available)\n",
        "data = pd.read_csv(\"Social_Network_Ads.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf6fA0LKv6bL",
        "outputId": "4731d798-031a-4d99-f064-191ceba0f085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 3 columns):\n",
            " #   Column           Non-Null Count  Dtype\n",
            "---  ------           --------------  -----\n",
            " 0   Age              400 non-null    int64\n",
            " 1   EstimatedSalary  400 non-null    int64\n",
            " 2   Purchased        400 non-null    int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 9.5 KB\n",
            "None\n",
            "Purchased\n",
            "0    257\n",
            "1    143\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Exploratory info\n",
        "print(data.info())\n",
        "print(data.Purchased.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o2B1uySxv8Hf"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "# Selecting relevant features and label\n",
        "X = data[['Age', 'EstimatedSalary']].values  # Features\n",
        "y = data['Purchased'].values  # Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "unKVbDB3wCPF"
      },
      "outputs": [],
      "source": [
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-y6B-sOhwEMa"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)  # Reshape to (n_samples, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X3c6ixWowGU6"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PY15yHvxvVU"
      },
      "outputs": [],
      "source": [
        "#to(device) ensures everything (model and data) runs on the same hardware,\n",
        "#maximizing performance and avoiding errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gxDl1huywI1D"
      },
      "outputs": [],
      "source": [
        "# Send data to device\n",
        "X_train, X_test = X_train.to(device), X_test.to(device)\n",
        "y_train, y_test = y_train.to(device), y_test.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3OIaeS7AwKYc"
      },
      "outputs": [],
      "source": [
        "# Define the ANN model\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(2, 8),  # Input layer -> Hidden layer  #Linear(input,output) ---> similar to Dense\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 4),  # Hidden layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4, 1),  # Output layer\n",
        "            nn.Sigmoid()      # Sigmoid for binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdS8Nat5wNHy"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = ANNModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha-LFBk8wPbs"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2oNKaK-wQ1C",
        "outputId": "425b8ae2-be90-442f-83bb-ff926136797b"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "    outputs = model(X_train)  # Forward pass on training data\n",
        "    loss = criterion(outputs, y_train)  # Compute loss on training predictions\n",
        "    loss.backward()  # Backpropagation to compute gradients\n",
        "    optimizer.step()  # Update weights using optimizer\n",
        "\n",
        "    # Compute training accuracy\n",
        "    predicted_train = (outputs > 0.5).float()\n",
        "    train_acc = accuracy_score(y_train.cpu(), predicted_train.cpu())\n",
        "\n",
        "    # Validation loss and accuracy\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_test)\n",
        "        val_loss = criterion(val_outputs, y_test)\n",
        "        predicted_val = (val_outputs > 0.5).float()\n",
        "        val_acc = accuracy_score(y_test.cpu(), predicted_val.cpu())\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39ny8ohZwSXk"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test)\n",
        "    predicted_classes = (predictions > 0.5).float()\n",
        "    acc = accuracy_score(y_test.cpu(), predicted_classes.cpu())\n",
        "    cm = confusion_matrix(y_test.cpu(), predicted_classes.cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwLGGGtbwT-i",
        "outputId": "d9046f7f-945e-460e-8cdc-dee4a3112a13"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTest Accuracy:\", acc)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ipykernel_py3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
